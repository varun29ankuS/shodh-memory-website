import type { Metadata } from "next";
import { Header } from "@/components/Header";
import { Footer } from "@/components/Footer";
import Link from "next/link";
import { notFound } from "next/navigation";
import { BLOG_POSTS } from "../page";

const BLOG_CONTENT: Record<string, string[]> = {
  "why-your-ai-agents-memory-is-broken": [
    "# Why Your AI Agent's Memory Is Broken — And How Neuroscience Fixes It",
    "",
    "Your AI agent is brilliant for exactly one conversation. Then it forgets everything.",
    "",
    "It forgets your tech stack. It forgets the architectural decision you made three hours ago. It forgets that you hate semicolons. Every session starts from zero — the same introductions, the same context-setting, the same wasted tokens re-explaining what it should already know.",
    "",
    "This isn't a minor inconvenience. It's a fundamental architectural failure. And the usual fixes — RAG, chat history, vector databases — don't solve it. They solve a different problem.",
    "",
    "The real fix comes from an unexpected place: 75 years of neuroscience research on how biological memory actually works.",
    "",
    "## The Broken State of Agent Memory",
    "",
    "### What Most Frameworks Ship",
    "",
    "Open any agent framework — LangChain, CrewAI, AutoGen, OpenAI's Agents SDK — and look at their memory implementation. You'll find one of three things:",
    "",
    "**1. Chat history buffers.** Every message appended to a list, sent back as context on the next turn. After 50 conversations this is 200K tokens of undifferentiated noise. There's no prioritization, no decay, no way to distinguish \"user prefers Rust\" from \"user said hello.\"",
    "",
    "**2. RAG pipelines.** Documents chunked, embedded, and stuffed into a vector database. When the agent needs context, it runs a similarity search. This retrieves relevant *documents* — but it doesn't remember *experiences*. The agent that helped you debug a race condition yesterday retrieves the same chunks whether it's seen the code once or fifty times.",
    "",
    "**3. Key-value stores.** Explicit `memory.set('preference', 'dark mode')` calls. Better than nothing, but this isn't memory — it's a configuration file. The agent can only remember things you explicitly tell it to remember, in the exact format you stored them.",
    "",
    "None of these exhibit the properties that make biological memory useful: selectivity, association, decay, or consolidation.",
    "",
    "### Why This Matters Now",
    "",
    "When agents were simple chatbots, statelessness was acceptable. But agents in 2026 are different:",
    "",
    "- **Coding agents** work on the same codebase for weeks. They need to remember architectural decisions, failed approaches, and developer preferences.",
    "- **Research agents** build understanding over multiple sessions. Each paper they read should inform how they read the next one.",
    "- **Workflow agents** coordinate across tools and time. A deployment agent needs to remember that the last deploy failed because of a missing env var — not repeat the same mistake.",
    "- **Multi-agent systems** share knowledge between specialized agents. The planning agent's decisions need to be accessible to the execution agent.",
    "",
    "Without memory, every agent interaction is a cold start. With memory, agents accumulate expertise.",
    "",
    "## What Neuroscience Already Solved",
    "",
    "The human brain solves the memory problem with a handful of elegant mechanisms, each discovered and validated through decades of research. Every single one translates directly to software.",
    "",
    "### 1. Hebbian Learning: Strengthen What Matters",
    "",
    "In 1949, Donald Hebb proposed a simple rule: neurons that fire together wire together. When two concepts are activated at the same time, the connection between them strengthens. This was later validated experimentally by Bi & Poo (1998), who measured actual synaptic strengthening rates of 3-7% per co-activation.",
    "",
    "**The software translation:** When an agent retrieves a memory and it turns out to be useful, strengthen that memory. When two memories are accessed together, strengthen the connection between them. Over time, frequently-useful knowledge becomes strongly encoded while noise stays weak.",
    "",
    "```",
    "# Hebbian update after co-access",
    "edge.weight += HEBBIAN_BOOST   # +0.025 per co-activation",
    "edge.weight *= HEBBIAN_DECAY   # *0.90 when unused",
    "",
    "# Asymmetric by design:",
    "# 40 co-accesses to reach 1.0 strength",
    "# 22 idle cycles to decay back to 0.1",
    "# Building is harder than forgetting — exactly like biology",
    "```",
    "",
    "This isn't a theoretical abstraction. The constants (0.025 additive boost, 0.90 multiplicative decay) are calibrated from Bi & Poo's measurements of hippocampal synaptic modification.",
    "",
    "### 2. Decay Curves: Forget Gracefully",
    "",
    "Ebbinghaus discovered forgetting curves in 1885. Wixted & Ebbesen (1991) refined them: forgetting follows a **power law**, not an exponential. The practical difference is enormous — exponential decay kills memories too fast in the first hours, while power-law decay preserves them longer but still lets truly unused information fade.",
    "",
    "**The software translation:** Every memory has a strength that decays over time. Recent memories decay exponentially (fast initial drop), then transition to power-law decay after 3 days (slow long-term fade). The crossover point comes from Wixted (2004)'s analysis of neural consolidation timelines.",
    "",
    "```",
    "if age < 3 days:",
    "    strength = e^(-λt)           # exponential: rapid initial decay",
    "else:",
    "    strength = (t + 1)^(-d)      # power-law: slow long-term fade",
    "",
    "# Memories accessed during decay get a strength boost",
    "# Creating the spacing effect: spaced retrieval > massed retrieval",
    "```",
    "",
    "The result: information that's accessed periodically stays strong indefinitely. Information that's never accessed again fades naturally, without any explicit garbage collection.",
    "",
    "### 3. Spreading Activation: Context Surfaces Automatically",
    "",
    "Anderson & Pirolli (1984) modeled how recalling one concept activates related concepts in a network. When you think of \"Python,\" concepts like \"Django,\" \"pip,\" and \"indentation\" get a partial activation boost — they become easier to recall even though you didn't explicitly search for them.",
    "",
    "**The software translation:** Memories are nodes in a knowledge graph. When a query activates one node, activation spreads through edges to related nodes, decaying by 0.7x per hop. The agent doesn't just retrieve the best vector match — it retrieves a *neighborhood* of related knowledge.",
    "",
    "```",
    "query: \"authentication bug\"",
    "",
    "Direct match:  \"JWT token expiry issue\" ............. 1.00",
    "1-hop:         \"auth middleware refactor\" ............ 0.70",
    "1-hop:         \"session cookie changes\" .............. 0.70",
    "2-hop:         \"Redis session store migration\" ....... 0.49",
    "2-hop:         \"user preference for httpOnly\" ........ 0.49",
    "",
    "# Vector search alone would miss the Redis migration",
    "# Graph traversal surfaces it because it's connected to sessions",
    "```",
    "",
    "This is why graph-enhanced retrieval beats vector-only retrieval by 13% on recall quality (Edge et al., 2024). The graph captures relationships that embedding similarity misses.",
    "",
    "### 4. Three-Tier Architecture: Not All Memories Are Equal",
    "",
    "Cowan (1988, 2001) proposed that human memory operates in nested tiers: a focus of attention (working memory), activated long-term memory (session), and dormant long-term storage. Each tier has different capacity, access speed, and persistence characteristics.",
    "",
    "**The software translation:** Three tiers with automatic promotion:",
    "",
    "```",
    "┌─────────────────────────────────┐",
    "│  ┌───────────────────────────┐  │",
    "│  │  ┌───────────────────┐    │  │",
    "│  │  │  Working Memory   │    │  │  ← seconds, last 4-7 items",
    "│  │  └───────────────────┘    │  │",
    "│  │     Session Memory        │  │  ← hours, current conversation",
    "│  └───────────────────────────┘  │",
    "│       Long-Term Memory          │  ← permanent, consolidated",
    "└─────────────────────────────────┘",
    "",
    "Promotion: Working → Session (30 min) → Long-Term (24 hours)",
    "Demotion: strength < threshold → drop to lower tier",
    "```",
    "",
    "Working memory is volatile and fast — the agent's scratchpad during a single reasoning chain. Session memory persists for the current conversation. Long-term memory survives across sessions, days, weeks. The 30-minute promotion threshold comes from McGaugh (2000)'s work on synaptic consolidation windows.",
    "",
    "### 5. Consolidation: Replay Strengthens Traces",
    "",
    "Rasch & Born (2013) showed that memory replay during sleep moves information from hippocampal (temporary) to cortical (permanent) storage. Important memories get replayed more frequently. Emotional memories get priority (LaBar & Cabeza, 2006).",
    "",
    "**The software translation:** Background maintenance cycles periodically replay high-importance memories, strengthening their connections and promoting them through tiers. Memories with high emotional valence (marked as important, associated with errors or breakthroughs) get priority replay.",
    "",
    "This is why an agent remembers a critical production bug fix better than a routine code formatting change — the system mirrors how biological memory prioritizes emotionally significant events.",
    "",
    "## The Failure Modes of Current Approaches",
    "",
    "Understanding the neuroscience makes the problems with current approaches obvious:",
    "",
    "### RAG: Retrieval Without Learning",
    "",
    "RAG retrieves the same chunks with the same relevance scores every time, regardless of whether the information was useful. There's no feedback loop. The agent that retrieved a wrong document and got corrected will retrieve the same wrong document next time — because the index never learned from the interaction.",
    "",
    "A Hebbian memory system would have weakened that association after the correction and strengthened the correct one.",
    "",
    "### Vector Databases: Similarity Without Context",
    "",
    "Vector similarity finds embeddings close in feature space. But \"close in feature space\" doesn't mean \"relevant to this agent's experience.\" Two code snippets can be embedding-similar but completely unrelated to the agent's current task. Conversely, two memories can be embedding-distant but strongly connected through the agent's experience graph.",
    "",
    "A graph-enhanced retrieval system captures both — semantic similarity from vectors and experiential relevance from the knowledge graph.",
    "",
    "### Chat History: Everything Without Prioritization",
    "",
    "Chat history treats every message as equally important. The architectural decision that shapes six months of development gets the same weight as \"thanks, looks good.\" Without decay and consolidation, the signal-to-noise ratio drops toward zero as history grows.",
    "",
    "A three-tier system with decay naturally separates signal from noise: important, frequently-accessed information consolidates into long-term memory while noise decays away.",
    "",
    "## What a Neuroscience-Grounded Memory System Looks Like",
    "",
    "Putting all five mechanisms together produces a system that behaves qualitatively differently from any RAG pipeline or chat history:",
    "",
    "**On first interaction:** The agent stores memories in working tier, extracts entities for the knowledge graph, and begins forming associations.",
    "",
    "**After a few sessions:** Frequently-accessed knowledge promotes to long-term storage. Important decisions and user preferences consolidate. The knowledge graph develops strong clusters around frequently-discussed topics.",
    "",
    "**After weeks of use:** The agent has a rich, personalized knowledge base. It knows your codebase, your preferences, your team's conventions. Asking it about authentication immediately activates related memories about your session handling, your JWT configuration, that bug you fixed in February. Context surfaces before you ask for it.",
    "",
    "**Information the agent doesn't need fades naturally.** That one-time discussion about a library you didn't end up using? It decays. The formatting preference you mentioned once? It weakens unless reinforced. No manual cleanup required.",
    "",
    "This is what neuroscience-grounded memory looks like in practice. Not a database with a vector index. Not a chat log with a search bar. A living, adaptive system that strengthens with use and decays with neglect — exactly like the biological memory it's modeled on.",
    "",
    "## The Implementation Gap",
    "",
    "The neuroscience has been settled for decades. Hebb published in 1949. Wixted's decay model is from 2004. Cowan's three-tier architecture is from 1988. Anderson's spreading activation is from 1984. None of this is new.",
    "",
    "The gap isn't knowledge — it's engineering. Building a memory system that implements all five mechanisms requires:",
    "",
    "- A **vector index** for semantic similarity (fast nearest-neighbor search)",
    "- A **knowledge graph** for entity relationships and spreading activation",
    "- A **decay engine** running continuously on stored memories",
    "- A **consolidation system** that promotes and demotes between tiers",
    "- A **Hebbian update loop** that strengthens connections on co-access",
    "- All of this running **locally**, with sub-millisecond writes, on commodity hardware",
    "",
    "That's what [shodh-memory](https://github.com/varun29ankuS/shodh-memory) implements. A single Rust binary that runs these five neuroscience mechanisms on localhost, exposing them as 45 MCP tools that any AI agent can use. Every tunable constant — the Hebbian boost rate, the decay crossover point, the spreading activation decay factor — is calibrated from the cited papers and documented in [src/constants.rs](https://github.com/varun29ankuS/shodh-memory/blob/main/src/constants.rs).",
    "",
    "## Getting Started",
    "",
    "```bash",
    "# Install the memory backend",
    "cargo install shodh-memory",
    "",
    "# Start the server",
    "shodh-memory",
    "",
    "# Connect any MCP client (Claude, Cursor, etc.)",
    "npx @shodh/memory-mcp@0.1.80",
    "```",
    "",
    "Or from Python:",
    "",
    "```python",
    "from shodh_memory.integrations.openai_agents import ShodhTools",
    "from agents import Agent, Runner",
    "",
    "tools = ShodhTools(user_id=\"my-agent\")",
    "agent = Agent(",
    "    name=\"memory-agent\",",
    "    tools=tools.as_list(),",
    "    instructions=\"You have persistent memory. Use it.\"",
    ")",
    "```",
    "",
    "The agent starts remembering from the first interaction. No configuration, no cloud setup, no API keys for external services. Just memory that works the way memory should work — grounded in the science of how memory actually functions.",
    "",
    "## Further Reading",
    "",
    "The research behind every mechanism:",
    "",
    "- [Memory Decay & Forgetting Curves](/blog/memory-decay-forgetting-curves) — Wixted's hybrid model",
    "- [Hebbian Learning in AI Agents](/blog/hebbian-learning-ai-agents) — From synapses to software",
    "- [Three-Tier Memory Architecture](/blog/three-tier-memory-architecture) — Cowan's embedded processes",
    "- [Knowledge Graph Spreading Activation](/blog/knowledge-graph-spreading-activation) — How context surfaces",
    "- [All Research & Citations](/research) — Every paper we cite, with BibTeX",
  ],
  "what-is-ai-agent-memory": [
    "# What Is AI Agent Memory? Beyond Chat History and RAG",
    "",
    "AI agents are the biggest shift in software since mobile. Coding assistants, research bots, autonomous workflows — they're everywhere. But ask any agent what you told it yesterday, and you'll get a blank stare.",
    "",
    "That's because most AI agents have no memory.",
    "",
    "Not \"limited memory.\" Not \"short-term memory.\" Literally none. Every invocation starts from zero. The agent that helped you refactor your authentication system yesterday has no idea it happened today.",
    "",
    "This article explains what AI agent memory actually is, why chat history and RAG don't solve it, and what a real memory system looks like.",
    "",
    "## The Problem: Stateless by Default",
    "",
    "Every major agent framework — OpenAI's Agents SDK, LangChain, CrewAI, AutoGen — runs agents as stateless functions. You provide instructions, tools, and a prompt. The agent reasons, acts, and returns a result. Then it's gone.",
    "",
    "Some frameworks offer \"memory\" features, but look closely and you'll find they're just appending chat messages to a list. That's not memory. That's a transcript.",
    "",
    "Real memory has properties that chat history doesn't:",
    "",
    "- **Selectivity** — Not everything is worth remembering. A memory system should strengthen important information and let noise fade.",
    "- **Association** — Memories connect to each other. Recalling one concept should activate related concepts.",
    "- **Decay** — Old, unused information should naturally fade. A system that never forgets is a system that can never prioritize.",
    "- **Consolidation** — Frequently accessed knowledge should become permanent. Rarely used knowledge should gradually disappear.",
    "",
    "These aren't nice-to-haves. They're the difference between an agent that learns and an agent that just executes.",
    "",
    "## What Agent Memory Is Not",
    "",
    "### It's Not Chat History",
    "",
    "Appending every message to a list gives you a transcript, not a memory. Chat history is linear, undifferentiated, and grows without bound. There's no mechanism for importance, no association between concepts, no decay of irrelevant information.",
    "",
    "After 50 conversations, a chat history is 200K tokens of noise. A memory system would have distilled that into a few hundred high-signal memories with connections between them.",
    "",
    "### It's Not RAG",
    "",
    "Retrieval-Augmented Generation retrieves documents based on query similarity. It's a search engine, not a memory system. RAG doesn't learn from interactions. It doesn't strengthen frequently-accessed knowledge. It doesn't form associations between concepts. It retrieves the same chunks whether you've asked about them once or a thousand times.",
    "",
    "RAG answers \"what documents are relevant to this query?\" Memory answers \"what does this agent know, and what matters most right now?\"",
    "",
    "### It's Not a Vector Database",
    "",
    "Vector databases store embeddings and retrieve by similarity. That's one component of a memory system — the retrieval layer. But memory also needs temporal awareness (when was this learned?), importance weighting (how often has this been accessed?), relationship tracking (what connects to what?), and lifecycle management (what should be forgotten?).",
    "",
    "A vector database is a tool. Memory is a system.",
    "",
    "## What Agent Memory Actually Is",
    "",
    "Agent memory is a cognitive system that encodes, stores, retrieves, and manages an agent's accumulated knowledge across sessions. It has several key properties:",
    "",
    "### Multi-Tier Storage",
    "",
    "Not all memories are equal. A memory system needs at least three tiers:",
    "",
    "- **Working memory** — Active context for the current task. Tiny capacity, instant access. Decays in minutes.",
    "- **Session memory** — What happened in this conversation. Medium capacity. Decays in hours to days.",
    "- **Long-term memory** — Consolidated knowledge that persists across sessions. Large capacity. Decays over weeks to months, or becomes permanent if frequently accessed.",
    "",
    "This mirrors how biological memory works. Nelson Cowan's embedded-processes model (2001) describes exactly this hierarchy — and it maps cleanly to engineering requirements.",
    "",
    "### Hebbian Learning",
    "",
    "\"Neurons that fire together wire together.\" When two memories are accessed in the same context, the connection between them strengthens. When they're not, the connection weakens.",
    "",
    "This means your agent's knowledge graph is self-organizing. It doesn't need manual curation. The structure emerges from usage patterns.",
    "",
    "### Forgetting Curves",
    "",
    "Hermann Ebbinghaus discovered in 1885 that forgetting follows a predictable curve. Modern research (Wixted 2004) shows it's a hybrid: exponential decay for recent memories, power-law decay for older ones.",
    "",
    "A memory system that implements forgetting curves naturally prioritizes recent, frequently-accessed knowledge while letting stale information fade. This isn't a bug — it's a feature. An agent that never forgets is an agent that drowns in irrelevant context.",
    "",
    "### Spreading Activation",
    "",
    "When you recall one concept, related concepts become more accessible. This is spreading activation — first described by Collins and Loftus (1975) and formalized for AI by Anderson and Pirolli (1984).",
    "",
    "In practice, this means when your agent is working on a database migration, memories about schema design, ORM configurations, and past migration issues all surface proactively — without being explicitly queried.",
    "",
    "## Why This Matters Now",
    "",
    "Three trends are converging:",
    "",
    "1. **Agents are going autonomous.** They're not chatbots waiting for prompts anymore. They run in the background, make decisions, and act. Without memory, they repeat the same mistakes endlessly.",
    "",
    "2. **Multi-agent systems are growing.** When multiple agents collaborate, they need shared context. Memory provides the coordination layer that prompt-passing can't.",
    "",
    "3. **Sessions are getting longer.** Agents that work on codebases, manage projects, or monitor systems need to maintain context across days, weeks, and months — not just within a single conversation.",
    "",
    "## How Shodh-Memory Implements This",
    "",
    "Shodh-memory is a cognitive memory system that implements all of the above in a single binary:",
    "",
    "```bash",
    "# Install via MCP (works with Claude Code, Cursor, Windsurf)",
    "npx @shodh/memory-mcp@latest",
    "```",
    "",
    "- **3-tier architecture** — Working, session, and long-term memory with automatic promotion",
    "- **Hebbian learning** — Connections strengthen with co-access, weaken without it",
    "- **Hybrid decay** — Exponential for recent, power-law for older memories (Wixted 2004)",
    "- **Knowledge graph** — Entity extraction and spreading activation for proactive context",
    "- **Sub-millisecond writes** — Async by default, <1ms per memory operation",
    "- **Runs offline** — Single ~30MB binary, no cloud dependency, works on Raspberry Pi",
    "",
    "The result: agents that genuinely learn from experience, surface relevant context before you ask, and maintain cognitive continuity across sessions.",
    "",
    "Memory isn't a feature you bolt on. It's a capability that transforms what agents can do.",
  ],
  "what-is-ai-memory": [
    "# What Is AI Memory? A Technical Guide for 2026",
    "",
    "Every AI system has a memory problem.",
    "",
    "GPT-4 can reason about complex problems but forgets your name between conversations. Claude can analyze entire codebases but loses context after the session ends. Your coding assistant re-discovers your project structure every morning.",
    "",
    "The industry has tried to solve this with bigger context windows, RAG pipelines, and conversation logs. None of these are memory. They're workarounds for the absence of memory.",
    "",
    "This guide explains what AI memory actually is — technically, not metaphorically — and why it's becoming the critical infrastructure layer for serious AI systems.",
    "",
    "## Defining AI Memory",
    "",
    "AI memory is a system that gives artificial intelligence the ability to encode, retain, retrieve, and manage knowledge across interactions over time. It has four core operations:",
    "",
    "1. **Encoding** — Transforming raw input (text, code, events) into structured, searchable representations",
    "2. **Storage** — Persisting those representations with metadata (timestamps, importance scores, relationships)",
    "3. **Retrieval** — Finding relevant memories based on semantic similarity, temporal recency, and associative connections",
    "4. **Management** — Strengthening important memories, decaying unused ones, consolidating patterns, forgetting noise",
    "",
    "If a system does encoding, storage, and retrieval but not management, it's a database. Management is what makes it memory.",
    "",
    "## The Memory Taxonomy",
    "",
    "### By Duration",
    "",
    "| Tier | Duration | Purpose | Example |",
    "| --- | --- | --- | --- |",
    "| Sensory buffer | Milliseconds | Raw input processing | Current token window |",
    "| Working memory | Seconds to minutes | Active reasoning context | Current task state |",
    "| Short-term / Session | Minutes to hours | Conversation continuity | This session's decisions |",
    "| Long-term | Days to permanent | Accumulated knowledge | User preferences, project patterns |",
    "",
    "Most AI systems only have the sensory buffer (context window). Everything else is missing infrastructure.",
    "",
    "### By Content Type",
    "",
    "- **Episodic memory** — Specific events and experiences (\"Last Tuesday, the deploy failed because of a missing env var\")",
    "- **Semantic memory** — General knowledge and facts (\"This project uses PostgreSQL with Prisma ORM\")",
    "- **Procedural memory** — How to do things (\"To deploy, run `make release` then `kubectl apply`\")",
    "",
    "A complete memory system handles all three types. Most current approaches only handle semantic memory (via embeddings) and ignore episodic and procedural entirely.",
    "",
    "## What AI Memory Is Not",
    "",
    "### Not a Context Window",
    "",
    "Context windows are the AI equivalent of sensory input. They hold what the model can currently \"see\" — nothing more. When the window fills up, information is lost. There's no persistence, no selectivity, no learning.",
    "",
    "Making context windows larger is like giving someone better eyesight but no ability to form memories. You can see more at once, but you still forget everything when you blink.",
    "",
    "### Not RAG (Retrieval-Augmented Generation)",
    "",
    "RAG retrieves documents from a static corpus based on query similarity. It's a search system, not a memory system. Key differences:",
    "",
    "| Aspect | RAG | Memory |",
    "| --- | --- | --- |",
    "| Source | Pre-indexed documents | Agent's own experiences |",
    "| Learning | None — corpus is static | Continuous — learns from interactions |",
    "| Importance | All chunks weighted equally | Frequently-accessed knowledge prioritized |",
    "| Relationships | None between chunks | Knowledge graph with associations |",
    "| Forgetting | Never — index only grows | Decay curves for natural prioritization |",
    "| Temporal | No time awareness | Full temporal context (when, how recent) |",
    "",
    "RAG answers: \"What documents match this query?\" Memory answers: \"What does this agent know, and what matters most right now?\"",
    "",
    "### Not a Vector Database",
    "",
    "A vector database is a component of a memory system, not a memory system itself. It handles one operation (similarity retrieval) out of the four required (encoding, storage, retrieval, management). Using a vector database as your memory system is like using a filing cabinet as your brain.",
    "",
    "## The Neuroscience Foundation",
    "",
    "AI memory systems that actually work draw from decades of cognitive science research:",
    "",
    "### Ebbinghaus Forgetting Curves (1885)",
    "",
    "Memories decay predictably over time. Recent research by Wixted (2004) shows the curve is hybrid — exponential for the first few days, then power-law for longer periods. This means recently-formed memories fade quickly unless reinforced, while older consolidated memories are remarkably stable.",
    "",
    "### Hebb's Rule (1949)",
    "",
    "\"Neurons that fire together wire together.\" When two pieces of knowledge are accessed in the same context, the connection between them strengthens. This creates self-organizing knowledge structures without manual curation.",
    "",
    "### Cowan's Embedded Processes (2001)",
    "",
    "Working memory is not a separate system — it's an activated subset of long-term memory. This model maps directly to engineering: working memory is a cache, session memory is a write-ahead log, and long-term memory is the persistent store.",
    "",
    "### Anderson's ACT-R Spreading Activation (1984)",
    "",
    "When one concept is activated in memory, activation spreads to related concepts through associative links. This is how context surfaces proactively — you don't need to query for related information, it emerges from the graph structure.",
    "",
    "## The Architecture of Real AI Memory",
    "",
    "A production-grade AI memory system needs five layers:",
    "",
    "### 1. Encoding Layer",
    "",
    "Transforms raw input into multi-dimensional representations. Embedding models (MiniLM-L6-v2, for example) convert text into 384-dimensional vectors. Named entity recognition extracts entities and relationships. Keyword extraction identifies important terms.",
    "",
    "### 2. Storage Layer",
    "",
    "Persists encoded memories with full metadata: timestamps, access counts, importance scores, source context, entity links, and tier classification. LSM-tree databases like RocksDB handle this well — fast writes, efficient range scans, built-in compression.",
    "",
    "### 3. Retrieval Layer",
    "",
    "Multi-signal retrieval combining vector similarity (semantic match), BM25 (keyword match), temporal recency (how recent), and graph traversal (spreading activation). A single retrieval mode isn't enough — you need reciprocal rank fusion across multiple signals.",
    "",
    "### 4. Knowledge Graph Layer",
    "",
    "Entities and relationships extracted from memories form a graph. This graph enables spreading activation, associative retrieval, and proactive context surfacing. Hebbian learning strengthens frequently co-activated edges.",
    "",
    "### 5. Lifecycle Management Layer",
    "",
    "Decay functions reduce memory importance over time. Consolidation promotes frequently-accessed memories to higher tiers. Long-Term Potentiation makes critical knowledge permanent. Garbage collection removes memories that have decayed below threshold.",
    "",
    "## Why 2026 Is the Inflection Point",
    "",
    "Three things changed:",
    "",
    "1. **MCP standardized tool communication.** The Model Context Protocol means memory systems can integrate with any AI host (Claude, GPT, Cursor, Windsurf) through a single interface. No custom integrations needed.",
    "",
    "2. **Agents went autonomous.** AI systems that run continuously — monitoring codebases, managing infrastructure, coordinating workflows — need memory that persists across invocations. Stateless doesn't work when the task spans weeks.",
    "",
    "3. **Edge deployment became real.** AI on drones, robots, and IoT devices can't call cloud APIs for every memory operation. Local-first memory with sub-millisecond latency isn't optional — it's a requirement.",
    "",
    "## Getting Started",
    "",
    "Shodh-memory implements all five layers in a single binary that runs on any platform:",
    "",
    "```bash",
    "# One command to add memory to Claude Code or Cursor",
    "npx @shodh/memory-mcp@latest",
    "```",
    "",
    "The system handles encoding, storage, retrieval, knowledge graph maintenance, and lifecycle management automatically. Memories strengthen with use, decay naturally, and surface proactively when relevant.",
    "",
    "AI memory isn't a feature. It's a fundamental capability — and it's the difference between AI that executes and AI that learns.",
  ],
  "why-ai-memory-should-be-local": [
    "# Why AI Memory Should Run Locally: Privacy, Latency & Sovereignty",
    "",
    "Your AI agent knows your codebase, your architecture decisions, your debugging patterns, your team's conventions, and your personal preferences. That's valuable knowledge.",
    "",
    "Now ask yourself: where is that knowledge stored?",
    "",
    "If you're using a cloud memory service, the answer is \"someone else's server.\" Your agent's accumulated knowledge — everything it has learned about you and your work — lives in a data center you don't control, governed by terms of service you probably haven't read.",
    "",
    "This isn't paranoia. It's an engineering reality that has concrete consequences for privacy, performance, and control.",
    "",
    "## The Privacy Argument",
    "",
    "### Your Memory Is Your Moat",
    "",
    "An AI agent's accumulated memory is arguably more valuable than its model weights. Model weights are commodity — everyone has access to GPT-4, Claude, and open-source alternatives. But an agent that has spent six months learning your codebase, your team's patterns, and your domain expertise? That's irreplaceable institutional knowledge.",
    "",
    "When you store this in a cloud service, you're handing over your competitive advantage. Cloud memory providers can analyze aggregate patterns, train on your data (check the ToS), or lose it in a breach.",
    "",
    "### Regulated Industries Can't Risk It",
    "",
    "Healthcare (HIPAA), finance (SOX, PCI-DSS), defense (ITAR), and government (FedRAMP) have strict data residency requirements. An AI agent that sends patient interaction patterns to a third-party cloud service is a compliance violation waiting to happen.",
    "",
    "Local memory eliminates the problem entirely. Data never leaves the machine.",
    "",
    "### PII Leakage Is Subtle",
    "",
    "Agent memory captures things that aren't obviously sensitive but are deeply personal: your debugging approach reveals how you think, your commit patterns reveal your work schedule, your question patterns reveal your knowledge gaps. Aggregated, this is a detailed profile of you and your team.",
    "",
    "Cloud providers aggregate data from thousands of users. Even with anonymization, re-identification is a known attack vector. Local memory creates no aggregate to attack.",
    "",
    "## The Latency Argument",
    "",
    "### Every Memory Operation Hits the Network",
    "",
    "Cloud memory means every remember, recall, and context lookup is a network round-trip. At best, that's 50-100ms on a good connection. At worst, it's 500ms+ on congested networks, mobile data, or international routes.",
    "",
    "Local memory operates in microseconds. Shodh-memory's async writes complete in under 1ms. Semantic search returns in 34-58ms (embedding generation dominates — the actual vector search is sub-millisecond).",
    "",
    "For an AI agent that checks memory dozens of times per task, the difference between local and cloud is the difference between fluid reasoning and constant stuttering.",
    "",
    "### Offline Doesn't Mean Disconnected",
    "",
    "Developers on planes, operators in factories, robots in warehouses, drones in the field — real-world AI agents frequently operate without reliable internet. A cloud memory system that goes down when WiFi drops is not production-grade.",
    "",
    "Local memory works everywhere. No connection required. The agent's knowledge is always available, always at full speed.",
    "",
    "### Tail Latencies Kill UX",
    "",
    "P50 latency tells you the best case. P99 tells you the real story. Cloud services that average 80ms often spike to 500ms+ under load, during deployments, or when routing changes. These tail latencies create unpredictable agent behavior — sometimes fast, sometimes inexplicably slow.",
    "",
    "Local memory has no tail latency problem. The storage is on the same machine. There's no network path to create variance.",
    "",
    "## The Sovereignty Argument",
    "",
    "### You Control the Data Lifecycle",
    "",
    "With local memory, you decide what's stored, how long it's kept, and when it's deleted. You can inspect the memory, audit it, export it, and destroy it. You have complete forensic capability.",
    "",
    "With cloud memory, you have an API that returns what the provider allows. Can you verify deletion? Can you prove data wasn't accessed? Can you audit who processed your memories? Usually not.",
    "",
    "### No Vendor Lock-In",
    "",
    "Cloud memory services create dependency. Your agent's knowledge lives in their format, on their infrastructure. Migration means rebuilding months of accumulated learning.",
    "",
    "Local memory in open formats means you own the data completely. Switch tools, switch providers, move to a different machine — your agent's knowledge follows you.",
    "",
    "### Geopolitical Risk Is Real",
    "",
    "Data stored in US cloud services is subject to the CLOUD Act. Data stored in Chinese cloud services is subject to Chinese national security law. For organizations operating across borders, where your AI's memory lives has legal implications.",
    "",
    "Local memory means data jurisdiction matches physical jurisdiction. Simple, predictable, and compliant by default.",
    "",
    "## The Counterarguments (And Why They're Weaker Than They Seem)",
    "",
    "### \"Cloud is easier to set up\"",
    "",
    "It was. Today, local memory can be a single binary with one install command. Shodh-memory is ~30MB, runs on everything from Raspberry Pi to cloud VMs, and needs zero configuration to start. The setup gap has closed.",
    "",
    "### \"Cloud scales better\"",
    "",
    "For what? Agent memory is per-user, per-agent. You're not serving millions of concurrent queries — you're storing one agent's knowledge. A single machine handles this trivially. Even at 100K memories, local vector search returns in milliseconds.",
    "",
    "### \"Cloud enables multi-device sync\"",
    "",
    "Fair point. But sync can happen on your terms — replicate to your own servers, use your own sync protocol, encrypt in transit. Cloud memory isn't required for multi-device; it's just the lazy path.",
    "",
    "### \"Local means managing infrastructure\"",
    "",
    "An embedded database in a single binary is not \"managing infrastructure.\" There's no server to maintain, no cluster to monitor, no scaling to configure. It's a file on disk.",
    "",
    "## How to Go Local",
    "",
    "Shodh-memory is built local-first from the ground up:",
    "",
    "```bash",
    "# Single binary, runs anywhere",
    "npx @shodh/memory-mcp@latest",
    "```",
    "",
    "- **Single binary** — ~30MB, no dependencies, no runtime",
    "- **Embedded storage** — RocksDB, no external database",
    "- **Embedded embeddings** — MiniLM-L6-v2 via ONNX, no API calls",
    "- **MCP protocol** — Works with Claude Code, Cursor, any MCP host",
    "- **Cross-platform** — Linux, macOS, Windows, ARM64 (Raspberry Pi)",
    "",
    "Your agent's memory stays on your machine. Period.",
    "",
    "The question isn't whether local memory is good enough. It's whether you can afford the risks of cloud memory. For most teams, the answer is becoming obvious.",
  ],
  "cognitive-memory-ai-arms-race": [
    "# Cognitive Memory: The Missing Piece in the AI Arms Race",
    "",
    "Every major AI lab is racing on the same capabilities: better reasoning, faster inference, more tools, larger context windows, cheaper tokens. The leaderboards track math benchmarks, coding challenges, and multi-hop question answering.",
    "",
    "But there's a capability that nobody is shipping: memory.",
    "",
    "Not context windows. Not RAG. Not conversation history. Real cognitive memory — the ability to learn from experience, strengthen important knowledge, forget noise, and build understanding over time.",
    "",
    "This is the biggest gap in the current AI stack, and the teams that fill it first will define the next era of AI applications.",
    "",
    "## The Arms Race So Far",
    "",
    "### Phase 1: Bigger Models (2020-2023)",
    "",
    "GPT-3, GPT-4, PaLM, LLaMA. The race was scale — more parameters, more training data, more compute. This phase gave us models that could reason, write code, and have conversations. But every conversation started from scratch.",
    "",
    "### Phase 2: Better Reasoning (2023-2025)",
    "",
    "Chain-of-thought, tree-of-thought, o1-style reasoning, tool use, function calling. Models got dramatically better at complex tasks within a single session. But they still forgot everything between sessions.",
    "",
    "### Phase 3: Agent Frameworks (2025-2026)",
    "",
    "OpenAI Agents SDK, LangGraph, CrewAI, AutoGen. The focus shifted from models to systems — agents that can plan, use tools, hand off tasks, and work autonomously. Massive progress on capability. Zero progress on continuity.",
    "",
    "### Phase 4: Memory (2026-?)",
    "",
    "This is where we are now. The realization that stateless agents hit a ceiling. An agent that can't learn from experience, can't build institutional knowledge, and can't maintain context across sessions isn't truly autonomous — it's a very sophisticated command executor.",
    "",
    "## Why Memory Is the Decisive Capability",
    "",
    "### Reasoning Without Memory Is Groundhog Day",
    "",
    "A coding agent with perfect reasoning but no memory will re-discover your project's architecture every session. It will re-learn your coding conventions. It will re-investigate the same bugs. It will ask the same questions about your deployment pipeline.",
    "",
    "Reasoning solves the \"how\" problem. Memory solves the \"what do we already know\" problem. Without memory, reasoning starts from zero every time. With memory, reasoning builds on accumulated knowledge.",
    "",
    "### Multi-Agent Systems Without Shared Memory Are Chaos",
    "",
    "When multiple agents work on a problem, they need shared context. Without memory, every agent has to be briefed from scratch. Coordination becomes a prompt engineering exercise — carefully crafting handoff messages to pass context between agents.",
    "",
    "With shared memory, agents can read from and write to a common knowledge base. Agent A discovers that the database schema changed. Agent B, working on the API layer, automatically has access to that context. No explicit handoff required.",
    "",
    "### Tool Use Without Memory Is Inefficient",
    "",
    "Agents use tools — search the web, query databases, run code. But without memory, the results of tool use are lost after the session. The agent will re-run the same searches, re-query the same databases, re-execute the same exploratory code.",
    "",
    "Memory means tool results persist. The agent that researched a library's API yesterday doesn't need to re-research it today. The competitive analysis from last week is still accessible. The benchmark results from the last sprint are ready for comparison.",
    "",
    "## What Makes Memory \"Cognitive\"",
    "",
    "Not all memory is equal. A key-value store with timestamps is not cognitive memory. What distinguishes cognitive memory:",
    "",
    "### 1. It Learns",
    "",
    "Cognitive memory implements Hebbian learning — connections between co-accessed concepts strengthen automatically. When you consistently access \"database\" memories in the context of \"migration\" memories, the system learns that these concepts are related. Over time, mentioning \"database\" proactively surfaces migration context.",
    "",
    "This is fundamentally different from static storage. The memory structure evolves with usage patterns.",
    "",
    "### 2. It Forgets",
    "",
    "Counterintuitively, forgetting is a feature, not a bug. A memory system that retains everything equally is a memory system that can't prioritize. Ebbinghaus forgetting curves ensure that unused information naturally fades, keeping the signal-to-noise ratio high.",
    "",
    "The math matters: hybrid exponential/power-law decay (Wixted 2004) mimics how biological memory actually works. Recent memories fade quickly unless reinforced. Older, consolidated memories are remarkably stable.",
    "",
    "### 3. It Associates",
    "",
    "Memories are not isolated data points — they exist in a web of relationships. A knowledge graph with spreading activation means that accessing one memory activates related memories, creating rich contextual retrieval that goes beyond simple similarity search.",
    "",
    "This is how humans think. You don't search your memory with a query — context triggers associated memories automatically.",
    "",
    "### 4. It Consolidates",
    "",
    "Working memory promotes to session memory. Session memory promotes to long-term memory. Frequently-accessed long-term memories undergo Long-Term Potentiation and become permanent. This tiered architecture means the system self-organizes — important knowledge naturally migrates to persistent storage.",
    "",
    "## The Competitive Landscape",
    "",
    "| System | Type | Learning | Forgetting | Association | Local |",
    "| --- | --- | --- | --- | --- | --- |",
    "| Chat history | Append log | None | None | None | Varies |",
    "| RAG | Document search | None | None | None | Varies |",
    "| Mem0 | Cloud memory | Limited | None | None | No |",
    "| Zep | Cloud memory | Limited | None | Basic | No |",
    "| Shodh-memory | Cognitive memory | Hebbian | Decay curves | Knowledge graph | Yes |",
    "",
    "The industry is still in the early stages. Most solutions are variations on \"vector database with some metadata.\" Cognitive memory — with genuine learning, forgetting, and association — is a fundamentally different approach.",
    "",
    "## What This Means for Builders",
    "",
    "If you're building AI agents, memory is the capability multiplier you're missing. An agent with memory:",
    "",
    "- **Onboards once, not every session** — Project context, team conventions, and domain knowledge persist",
    "- **Gets better over time** — Frequently-used knowledge strengthens, creating a personalized knowledge base",
    "- **Coordinates without orchestration** — Shared memory replaces explicit context-passing between agents",
    "- **Handles long-running tasks** — Multi-day workflows maintain full context",
    "",
    "```bash",
    "# Add cognitive memory to any MCP-compatible AI host",
    "npx @shodh/memory-mcp@latest",
    "```",
    "",
    "The AI arms race has been about making models smarter. The next phase is making them wiser — and wisdom requires memory.",
  ],
  "robotics-needs-memory": [
    "# Why Robotics Still Doesn't Have Memory (And How to Fix It)",
    "",
    "A modern industrial robot can identify objects with 99.7% accuracy, plan collision-free paths in milliseconds, and execute movements with sub-millimeter precision. It can do things no human worker can match.",
    "",
    "But ask it what it learned yesterday, and it has nothing to tell you.",
    "",
    "Despite decades of advances in perception, planning, and control, robotics has largely ignored memory. Robots don't remember what they've learned on the job. They don't build knowledge from experience. Every shift starts from the same programmed baseline.",
    "",
    "This is the biggest unexploited opportunity in robotics — and the gap is finally closeable.",
    "",
    "## The Current State: Brilliant but Amnesiac",
    "",
    "### Perception Is Solved (Mostly)",
    "",
    "Modern robots use depth cameras, LiDAR, tactile sensors, and vision transformers to understand their environment. Object detection, pose estimation, and scene understanding have reached human-level or better on standard benchmarks.",
    "",
    "### Planning Is Solved (Mostly)",
    "",
    "Motion planning algorithms (RRT*, OMPL) generate collision-free trajectories in real-time. Task planners (PDDL-based, LLM-augmented) decompose high-level goals into executable sequences. Path optimization handles dynamic obstacles.",
    "",
    "### Control Is Solved (Mostly)",
    "",
    "Force-torque control, impedance control, and compliant manipulation let robots handle fragile objects, perform insertion tasks, and adapt to contact forces. Hardware has caught up to the algorithms.",
    "",
    "### Memory Is Not Solved",
    "",
    "What happens when a pick-and-place robot encounters a new object shape? It runs inference from scratch. When a warehouse robot discovers an efficient route? Lost at reboot. When a surgical robot learns a surgeon's preferences? Gone after the session.",
    "",
    "The robot industry has world-class perception, planning, and control. It has essentially zero memory infrastructure.",
    "",
    "## Why Robots Need Memory",
    "",
    "### 1. Environmental Adaptation",
    "",
    "Real-world environments change. Warehouse layouts shift. Factory floors get reorganized. New products appear on the line. A robot without memory treats every change as a novel situation, requiring re-calibration or re-programming.",
    "",
    "A robot with memory accumulates knowledge about environmental changes over time. It remembers that aisle 7 was rearranged last month, that the new packaging is 2mm wider than the old one, and that the conveyor belt speed increases during the 2PM shift change.",
    "",
    "### 2. Skill Accumulation",
    "",
    "Robots learn tasks through demonstration, reinforcement learning, or programming. But learned skills are stored in model weights or configuration files — not in a queryable, associative memory system.",
    "",
    "Memory enables a fundamentally different approach: the robot accumulates micro-skills from experience. Each successful grasp adds to a knowledge base of object-specific strategies. Each failed placement refines future attempts. Over weeks and months, the robot builds a personalized repertoire that no amount of pre-training can match.",
    "",
    "### 3. Human Collaboration",
    "",
    "Collaborative robots (cobots) work alongside humans. Effective collaboration requires understanding preferences, habits, and communication patterns. Without memory, every shift with a new operator starts from zero.",
    "",
    "With memory, the cobot learns that Operator A prefers parts presented at 45 degrees, Operator B likes a faster cycle time, and Operator C needs more clearance on the left side. These preferences persist across sessions and improve collaboration quality over time.",
    "",
    "### 4. Predictive Maintenance",
    "",
    "Robots degrade. Joints wear, sensors drift, grippers lose grip strength. A robot without memory can only detect failure after it happens. A robot with memory tracks degradation patterns: \"Joint 3 torque has increased 12% over the last 3000 cycles, similar to the pattern before the last bearing failure.\"",
    "",
    "This is predictive maintenance at the agent level — not just sensor monitoring, but experiential knowledge of what degradation patterns mean.",
    "",
    "## Why It Hasn't Been Solved",
    "",
    "### Cloud Doesn't Work for Robots",
    "",
    "The obvious approach — store memories in the cloud — fails for robotics. Factory robots operate on isolated networks. Field robots (agriculture, construction, defense) have intermittent connectivity at best. Latency requirements for real-time systems are incompatible with cloud round-trips.",
    "",
    "A robot that pauses for 200ms to query cloud memory while performing a pick operation is a robot that drops things.",
    "",
    "### ROS Doesn't Have a Memory Layer",
    "",
    "ROS (Robot Operating System), the dominant robotics framework, has excellent support for perception (sensor fusion), planning (MoveIt), and control (ros_control). It has no built-in memory system. Developers who need persistence use SQLite, flat files, or ROS parameters — none of which provide semantic search, association, or decay.",
    "",
    "### Resource Constraints Are Real",
    "",
    "Edge computing platforms (NVIDIA Jetson, Raspberry Pi, industrial PCs) have limited RAM, storage, and compute. Memory systems designed for cloud servers — with heavy Python dependencies, large embedding models, and database servers — don't fit.",
    "",
    "A memory system for robotics needs to run in megabytes, not gigabytes. It needs to start in seconds, not minutes. It needs to survive power cycles without corruption.",
    "",
    "## What a Robot Memory System Needs",
    "",
    "Based on the constraints above, a memory system for robotics requires:",
    "",
    "| Requirement | Why | Target |",
    "| --- | --- | --- |",
    "| Sub-millisecond writes | Real-time operation can't wait | <1ms async writes |",
    "| Local-first | No network dependency | Embedded database |",
    "| Small footprint | Edge hardware constraints | <50MB total (binary + model) |",
    "| Crash-safe | Power cycles and hard reboots | WAL + checksums |",
    "| Semantic search | Find relevant past experiences | Embedded vector search |",
    "| Temporal awareness | \"What happened in the last hour?\" | Time-indexed storage |",
    "| Decay and consolidation | Don't run out of storage | Automatic lifecycle |",
    "| Cross-platform | ARM64, x86, Linux variants | Single compiled binary |",
    "",
    "## Shodh-Memory for Robotics",
    "",
    "Shodh-memory was designed for exactly this use case — cognitive memory that runs on edge devices:",
    "",
    "```bash",
    "# On a Raspberry Pi 4 or NVIDIA Jetson",
    "curl -L https://github.com/varun29ankuS/shodh-memory/releases/download/v0.1.80/shodh-memory-aarch64-linux -o shodh-memory",
    "chmod +x shodh-memory",
    "./shodh-memory",
    "```",
    "",
    "- **~30MB total** — Binary (25MB) + ONNX runtime (14MB), fits on any edge device",
    "- **Sub-millisecond writes** — Async mode doesn't block robot control loops",
    "- **Embedded everything** — RocksDB storage, MiniLM-L6-v2 embeddings, no external services",
    "- **ARM64 native** — Cross-compiled for Raspberry Pi, Jetson, and industrial ARM platforms",
    "- **REST API** — Simple HTTP interface that works from any language (Python, C++, ROS nodes)",
    "- **Hebbian learning** — Robot builds associative knowledge from experience automatically",
    "- **Decay curves** — Old operational data fades naturally, preventing storage bloat",
    "",
    "### Example: Pick-and-Place Learning",
    "",
    "```python",
    "import requests",
    "",
    "SHODH = \"http://localhost:3030/api\"",
    "",
    "# After a successful grasp",
    "requests.post(f\"{SHODH}/remember\", json={",
    "    \"content\": \"Object: red_cylinder. Grasp: top-down, 85mm opening. Force: 12N. Result: success. Cycle: 4.2s\",",
    "    \"memory_type\": \"Learning\",",
    "    \"tags\": [\"grasp\", \"red_cylinder\", \"success\"],",
    "})",
    "",
    "# Before attempting a new grasp — recall past experience",
    "response = requests.post(f\"{SHODH}/recall\", json={",
    "    \"query\": \"best grasp strategy for cylindrical objects\",",
    "    \"limit\": 5,",
    "})",
    "past_strategies = response.json()",
    "```",
    "",
    "Over hundreds of cycles, the robot builds a rich knowledge base of object-specific strategies. New objects benefit from transfer — similar shapes activate related grasp memories through spreading activation.",
    "",
    "## The Opportunity",
    "",
    "Robotics is a $70B+ market growing at 25% CAGR. Every major robotics company is investing in AI — better perception, better planning, better control. Almost none are investing in memory.",
    "",
    "The robots that remember will outperform the robots that don't. Not by a small margin — by a compounding margin that grows with every shift, every cycle, and every exception they learn from.",
    "",
    "The memory layer for robotics isn't coming someday. It's available now.",
  ],
  "openai-agents-sdk-cognitive-memory": [
    "# Giving OpenAI Agents Cognitive Memory: Shodh-Memory + Agents SDK",
    "",
    "OpenAI's Agents SDK launched with a compelling premise: give LLMs tools, handoffs, and guardrails — then let them reason through multi-step tasks autonomously. It's the cleanest framework for building production agents in Python.",
    "",
    "But there's a gap. Agents built with the SDK are stateless by default. Every run starts fresh. The agent that helped you debug a Kubernetes issue yesterday has zero memory of it today. Your multi-agent pipeline re-discovers the same project context on every invocation.",
    "",
    "This isn't a limitation of the SDK — it's a missing layer. The SDK provides a Session protocol for persistence and a FunctionTool interface for capabilities. What it needs is a memory system that actually thinks.",
    "",
    "That's what shodh-memory provides.",
    "",
    "## What Makes This Different from a Database",
    "",
    "You could store conversation history in SQLite. You could dump embeddings into Pinecone. But that's storage, not cognition.",
    "",
    "Shodh-memory implements biological memory dynamics:",
    "",
    "- Memories strengthen with repeated access (Hebbian learning — neurons that fire together wire together)",
    "- Unused memories decay naturally following Ebbinghaus forgetting curves (exponential for recent, power-law for older)",
    "- Related concepts activate each other through spreading activation in a knowledge graph",
    "- Memories promote through tiers: working → session → long-term, just like Cowan's embedded-processes model",
    "- Frequently-accessed knowledge undergoes Long-Term Potentiation and becomes permanent",
    "",
    "This means your agent doesn't just \"store and retrieve.\" It learns. Context that matters gets stronger. Noise fades. Connections form between related experiences.",
    "",
    "## Two Integration Points",
    "",
    "The shodh-memory adapter for OpenAI Agents SDK provides two components:",
    "",
    "### 1. ShodhSession — Automatic Conversation Memory",
    "",
    "The SDK's Session protocol lets you persist conversation state across runs. ShodhSession implements this with cognitive memory instead of flat storage:",
    "",
    "```python",
    "from shodh_memory.integrations.openai_agents import ShodhSession",
    "from agents import Agent, Runner",
    "",
    "session = ShodhSession(",
    "    session_id=\"project-alpha\",",
    "    user_id=\"engineer-1\",",
    "    api_key=\"your-key\",",
    ")",
    "",
    "agent = Agent(",
    "    name=\"Assistant\",",
    "    instructions=\"You are a helpful engineering assistant.\",",
    ")",
    "",
    "# First conversation",
    "result = await Runner.run(",
    "    agent,",
    "    \"We're migrating from PostgreSQL to CockroachDB.\",",
    "    session=session,",
    ")",
    "",
    "# Hours later — agent remembers the migration context",
    "result = await Runner.run(",
    "    agent,",
    "    \"What should I watch out for with distributed transactions?\",",
    "    session=session,",
    ")",
    "```",
    "",
    "Every conversation turn is encoded as a memory. When the agent runs again, previous context is retrieved through semantic search — not just replayed sequentially. The agent recalls what's relevant to the current query, not just the last N messages.",
    "",
    "Sessions are isolated by session_id. Different projects, different conversations, no bleed-through.",
    "",
    "### 2. ShodhTools — Explicit Memory Operations",
    "",
    "Sometimes agents need direct control over memory. ShodhTools provides 8 FunctionTool instances that agents can invoke:",
    "",
    "```python",
    "from shodh_memory.integrations.openai_agents import ShodhTools",
    "from agents import Agent, Runner",
    "",
    "tools = ShodhTools(",
    "    user_id=\"engineer-1\",",
    "    api_key=\"your-key\",",
    ")",
    "",
    "agent = Agent(",
    "    name=\"Memory Agent\",",
    "    instructions=(",
    "        \"You have persistent cognitive memory. \"",
    "        \"Use shodh_remember to store important facts, \"",
    "        \"shodh_recall to search your memory, \"",
    "        \"and shodh_add_todo for task tracking.\"",
    "    ),",
    "    tools=tools.as_list(),",
    ")",
    "",
    "result = await Runner.run(",
    "    agent,",
    "    \"Remember that the auth service uses JWT with RS256, \"",
    "    \"and add a todo to rotate the signing keys next sprint.\",",
    ")",
    "```",
    "",
    "The agent decides what to remember and when to recall. The LLM handles reasoning; shodh-memory handles persistence.",
    "",
    "| Tool | What It Does |",
    "|------|-------------|",
    "| shodh_remember | Store a memory with type (Decision, Learning, Error, etc.) and tags |",
    "| shodh_recall | Semantic search across all memories — hybrid vector + keyword |",
    "| shodh_forget | Remove a memory (corrections, outdated facts) |",
    "| shodh_context_summary | Get a condensed view of recent learnings and decisions |",
    "| shodh_proactive_context | Surface memories relevant to the current conversation |",
    "| shodh_add_todo | Create a task with project, priority, and due date |",
    "| shodh_list_todos | List tasks filtered by status or project |",
    "| shodh_complete_todo | Mark a task done (recurring tasks auto-create the next occurrence) |",
    "",
    "## Architecture: What Happens Under the Hood",
    "",
    "When an agent calls shodh_remember, here's what actually happens:",
    "",
    "```",
    "Agent calls shodh_remember(\"Auth uses JWT RS256\")",
    "  → HTTP POST to shodh-memory server (localhost:3030)",
    "  → Content embedded via MiniLM-L6-v2 (384-dim, ONNX, <5ms)",
    "  → Stored in RocksDB with MessagePack serialization",
    "  → Indexed in Vamana graph for approximate nearest neighbor search",
    "  → Entities extracted (\"JWT\", \"RS256\", \"auth service\")",
    "  → Knowledge graph updated — edges form between related entities",
    "  → Hebbian weights adjusted for co-accessed memories",
    "```",
    "",
    "When the agent later calls shodh_recall(\"authentication setup\"):",
    "",
    "```",
    "Agent calls shodh_recall(\"authentication setup\")",
    "  → Query embedded via same MiniLM model",
    "  → Multi-stage retrieval: vector search → BM25 rerank → temporal boost → graph expansion",
    "  → Spreading activation surfaces related memories (JWT → signing keys → rotation schedule)",
    "  → Accessed memories get a Hebbian strength boost (+0.025)",
    "  → Results returned ranked by composite relevance score",
    "```",
    "",
    "The key insight: every recall makes those memories stronger. The more your agent uses a piece of knowledge, the harder it becomes to forget. This is biological learning applied to AI systems.",
    "",
    "## Why Not Just Use SQLite or Redis?",
    "",
    "You could implement the Session protocol with SQLite. Store messages, retrieve them in order. It works.",
    "",
    "But you'd get flat storage. No semantic search — just sequential replay. No decay — your session grows unbounded. No learning — accessing a memory doesn't make it stronger. No graph — related concepts don't activate each other.",
    "",
    "| Feature | SQLite/Redis | Shodh-Memory |",
    "|---------|-------------|--------------|",
    "| Storage | Sequential messages | Semantic memories |",
    "| Retrieval | By index/key | By meaning (hybrid vector + keyword) |",
    "| Decay | Manual cleanup | Automatic (Ebbinghaus curves) |",
    "| Learning | None | Hebbian (strengthens with use) |",
    "| Context | Last N messages | Relevant memories from any point |",
    "| Connections | None | Knowledge graph with spreading activation |",
    "| Task tracking | Not built-in | Full GTD system |",
    "",
    "The difference is between a filing cabinet and a brain.",
    "",
    "## Running It",
    "",
    "Shodh-memory runs as a single binary — no Docker, no cloud, no API keys to manage:",
    "",
    "```",
    "# Install",
    "pip install shodh-memory[openai-agents]",
    "",
    "# Start the server (downloads MiniLM model on first run)",
    "shodh-memory serve",
    "",
    "# Or download the binary directly",
    "# https://github.com/varun29ankuS/shodh-memory/releases",
    "```",
    "",
    "Everything runs locally. Your agent's memories never leave your machine. Embeddings are computed locally via ONNX Runtime. Storage is local RocksDB. No cloud dependency whatsoever.",
    "",
    "## Combining Both: Session + Tools",
    "",
    "The most powerful pattern combines automatic session memory with explicit tool control:",
    "",
    "```python",
    "from shodh_memory.integrations.openai_agents import ShodhSession, ShodhTools",
    "from agents import Agent, Runner",
    "",
    "session = ShodhSession(",
    "    session_id=\"project-alpha\",",
    "    user_id=\"engineer-1\",",
    ")",
    "",
    "tools = ShodhTools(user_id=\"engineer-1\")",
    "",
    "agent = Agent(",
    "    name=\"Project Assistant\",",
    "    instructions=(",
    "        \"You have persistent cognitive memory. \"",
    "        \"Conversation history is automatic. \"",
    "        \"Use shodh_remember for important decisions, \"",
    "        \"shodh_recall to search past context, \"",
    "        \"and shodh_add_todo to track work items.\"",
    "    ),",
    "    tools=tools.as_list(),",
    ")",
    "",
    "# Session handles conversation continuity",
    "# Tools handle explicit memory operations",
    "result = await Runner.run(",
    "    agent,",
    "    \"What did we decide about the caching strategy?\",",
    "    session=session,",
    ")",
    "```",
    "",
    "The session provides continuity — the agent knows what you discussed before. The tools provide agency — the agent can explicitly remember decisions, recall past context, and track tasks.",
    "",
    "## Multi-Agent Memory",
    "",
    "Different agents can share a memory pool by using the same user_id, or maintain isolated memories with different user_ids. This enables patterns like:",
    "",
    "- A research agent stores findings → an implementation agent recalls them",
    "- A code review agent remembers past issues → a writing agent avoids them",
    "- Multiple specialized agents contribute to a shared project knowledge base",
    "",
    "The knowledge graph connects insights across agents. When one agent stores \"prefer Rust for performance-critical paths\" and another stores \"the hot loop is in the parser,\" a recall query about \"parser optimization\" surfaces both — because the graph links performance → Rust and parser → hot loop.",
    "",
    "## What This Means for Agent Builders",
    "",
    "The OpenAI Agents SDK gives you the scaffolding for capable agents. But capability without memory is amnesia with good reasoning.",
    "",
    "Adding shodh-memory takes five lines of code and gives your agent:",
    "",
    "- Cross-session continuity that actually understands context",
    "- Memories that strengthen with use and decay when irrelevant",
    "- A knowledge graph that connects concepts automatically",
    "- Task management that persists across conversations",
    "- Complete privacy — everything stays on your hardware",
    "",
    "The difference between an agent that's useful once and an agent that gets better over time is memory. Not storage. Cognition.",
    "",
    "---",
    "",
    "*shodh-memory is open-source (Apache 2.0) and available at github.com/varun29ankuS/shodh-memory. Install the OpenAI Agents adapter with: pip install shodh-memory[openai-agents]*",
  ],
  "rag-is-not-memory": [
    "# RAG Is Not Memory: Why Your AI Still Has Amnesia",
    "",
    "The conversation usually goes like this:",
    "",
    "\"We need our AI to remember things.\"",
    "\"Just add RAG.\"",
    "",
    "And then everyone moves on, thinking the problem is solved. It isn't.",
    "",
    "## What RAG Actually Does",
    "",
    "Retrieval-Augmented Generation is simple: when a user asks a question, search a database for relevant documents, stuff them into the context window, and generate a response.",
    "",
    "```",
    "User query → Vector search → Retrieved docs → LLM → Response",
    "```",
    "",
    "This is powerful for knowledge bases. Ask about your company's refund policy? RAG finds the policy document and the LLM summarizes it. Great.",
    "",
    "But this isn't memory. It's search.",
    "",
    "## The Difference: Retrieval vs. Remembering",
    "",
    "Memory isn't just \"find relevant information.\" Memory is a living system that:",
    "",
    "| RAG (Retrieval) | Memory |",
    "|-----------------|--------|",
    "| Static documents | Dynamic experiences |",
    "| You query it | It surfaces proactively |",
    "| All items equal | Importance varies |",
    "| Never forgets | Decays intelligently |",
    "| No learning | Strengthens with use |",
    "| Isolated facts | Connected concepts |",
    "",
    "Let's unpack each.",
    "",
    "### Static vs. Dynamic",
    "",
    "RAG databases contain documents. PDFs, web pages, knowledge articles. They're written once and retrieved later.",
    "",
    "Memory contains experiences. \"The user debugged a tricky async bug on Tuesday.\" \"The user prefers explicit error handling.\" \"The user's production database is PostgreSQL 15.\"",
    "",
    "These aren't documents. They're learned observations that accumulate over time.",
    "",
    "### Query vs. Proactive",
    "",
    "RAG only works when you ask. No query, no retrieval.",
    "",
    "Memory should surface context before you ask. When you start discussing database optimization, a memory system should automatically recall: \"This user's system uses PostgreSQL, and they mentioned query performance issues last week.\"",
    "",
    "This is spreading activation—thinking of one concept primes related concepts. RAG has no equivalent.",
    "",
    "### Equal vs. Weighted",
    "",
    "In RAG, all documents have equal standing. The refund policy from 2019 and the one from 2024 are just vectors in a space.",
    "",
    "Memory has importance. Some things matter more. \"User's deployment target is Kubernetes\" is load-bearing knowledge. \"User once mentioned liking dark mode\" is trivia. Memory systems should weight these differently.",
    "",
    "### Permanent vs. Decaying",
    "",
    "RAG databases are append-only. Everything you add stays forever (unless manually deleted).",
    "",
    "Memory should forget. Intelligently. Old context that's never accessed should fade. Frequently-used knowledge should strengthen. This is how human memory works, and it's essential for maintaining signal-to-noise ratio over time.",
    "",
    "### Static vs. Learning",
    "",
    "RAG doesn't learn from access patterns. Retrieve a document once or a thousand times—no difference.",
    "",
    "Memory should strengthen with use. If you access \"user prefers Rust\" every day for a month, that connection should become permanent (Long-Term Potentiation). If you never access \"user tried Python once,\" it should fade.",
    "",
    "### Isolated vs. Connected",
    "",
    "RAG returns documents. Each is an island.",
    "",
    "Memory forms a graph. Concepts connect to related concepts. \"PostgreSQL\" connects to \"database,\" which connects to \"performance,\" which connects to that optimization discussion from last week. Accessing one node activates related nodes.",
    "",
    "## The Practical Failures of RAG-as-Memory",
    "",
    "### Failure 1: No Cross-Session Continuity",
    "",
    "```",
    "Session 1: \"I'm using Next.js with App Router for this project.\"",
    "RAG: [stores document about Next.js project]",
    "",
    "Session 2: \"How should I structure my API routes?\"",
    "RAG: [retrieves generic API documentation]",
    "     → No memory of App Router preference",
    "```",
    "",
    "RAG retrieved something. But it didn't remember the architectural decision from session 1.",
    "",
    "### Failure 2: No Learning",
    "",
    "```",
    "Day 1: User prefers functional programming → RAG stores this",
    "Day 2: User asks about loops → RAG suggests for loops",
    "Day 3: User corrects: \"I prefer map/filter\" → RAG stores this",
    "Day 4: User asks about iteration → RAG might retrieve Day 1 OR Day 3",
    "```",
    "",
    "RAG doesn't know that Day 3 reinforced Day 1. It has two separate documents. A memory system would have strengthened the \"functional programming\" preference.",
    "",
    "### Failure 3: Noise Accumulation",
    "",
    "After a year of use, your RAG database has:",
    "- 47 mentions of debugging sessions",
    "- 23 architectural decisions",
    "- 156 random questions",
    "- 12 core user preferences",
    "",
    "Everything competes equally in vector space. The signal (core preferences) drowns in noise (random sessions). Without decay, retrieval quality collapses.",
    "",
    "## What Real Memory Looks Like",
    "",
    "A proper memory architecture has:",
    "",
    "```",
    "┌─────────────────────────────────────────────────────────────┐",
    "│  SENSORY BUFFER → WORKING MEMORY → LONG-TERM MEMORY        │",
    "│       ↓                 ↓                  ↓                │",
    "│   Raw input       Active context      Persistent store     │",
    "│   (7 items)       (4 chunks)          (unlimited)          │",
    "│   (30 sec TTL)    (minutes)           (decay + LTP)        │",
    "└─────────────────────────────────────────────────────────────┘",
    "                              +",
    "┌─────────────────────────────────────────────────────────────┐",
    "│  KNOWLEDGE GRAPH                                            │",
    "│  Entities → Relationships → Spreading Activation            │",
    "│  Hebbian Learning: connections strengthen with co-access    │",
    "└─────────────────────────────────────────────────────────────┘",
    "                              +",
    "┌─────────────────────────────────────────────────────────────┐",
    "│  TEMPORAL INDEX                                             │",
    "│  When things happened → Recency bias → Session context      │",
    "└─────────────────────────────────────────────────────────────┘",
    "```",
    "",
    "This is what shodh-memory implements. Not search. Memory.",
    "",
    "## When RAG Is Actually Right",
    "",
    "RAG is the right tool when you have:",
    "",
    "- **Static knowledge**: Documentation, policies, reference material",
    "- **No personalization needed**: Same answers for everyone",
    "- **Point-in-time queries**: \"What does the manual say about X?\"",
    "",
    "RAG is the wrong tool when you need:",
    "",
    "- **Personalization**: Remembering user preferences",
    "- **Learning**: Improving over time",
    "- **Proactive context**: Surfacing relevant info automatically",
    "- **Continuity**: Building on past sessions",
    "",
    "## The Hybrid Approach",
    "",
    "Smart systems use both:",
    "",
    "```python",
    "def get_context(query):",
    "    # RAG for static knowledge",
    "    docs = rag.search(query)",
    "    ",
    "    # Memory for dynamic context",
    "    memories = memory.proactive_context(query)",
    "    ",
    "    # Combine with appropriate weighting",
    "    return fuse(docs, memories, weights=[0.3, 0.7])",
    "```",
    "",
    "RAG handles \"what does the documentation say?\" Memory handles \"what does the user care about?\"",
    "",
    "## The Takeaway",
    "",
    "Next time someone says \"just add RAG\" to solve the memory problem, push back.",
    "",
    "Ask: Does it learn? Does it forget? Does it connect concepts? Does it surface proactively?",
    "",
    "If the answer is no, you've built a search engine, not a memory system.",
    "",
    "And your AI still has amnesia.",
    "",
    "---",
    "",
    "*shodh-memory is a cognitive memory system that actually remembers. Hebbian learning, intelligent decay, knowledge graphs, and proactive context. Not just retrieval. Check it out at [github.com/varun29ankuS/shodh-memory](https://github.com/varun29ankuS/shodh-memory).*",
  ],
  "agentic-shift-2026": [
    "# The Agentic Shift: Why 2026 Is the Year AI Stops Waiting for Prompts",
    "",
    "Something fundamental is changing. If you've been building with AI, you've felt it. The tools are different now. The expectations are different. The entire paradigm is shifting.",
    "",
    "We're moving from AI that waits to AI that acts.",
    "",
    "## The Prompt Era Is Ending",
    "",
    "For the past three years, AI interaction meant one thing: write a prompt, get a response, repeat. ChatGPT, Claude, Gemini—all glorified text boxes. You ask, they answer, you ask again.",
    "",
    "This worked. Sort of. But it had a fundamental limitation: the human was the bottleneck.",
    "",
    "Every task required human initiation. Human follow-up. Human context management. You had to remember what you discussed last week. You had to break complex tasks into tiny steps. You had to babysit.",
    "",
    "In 2026, this is starting to look quaint.",
    "",
    "## What's Actually Changing",
    "",
    "Three shifts are happening simultaneously:",
    "",
    "### 1. From Responses to Actions",
    "",
    "The new breed of AI doesn't just tell you what to do—it does it. Claude Code edits files. Cursor writes functions. Devin commits code. These aren't chat interfaces with syntax highlighting. They're agents with tool access.",
    "",
    "```",
    "Old: \"How do I fix this TypeScript error?\"",
    "     → Here's the solution, go apply it yourself",
    "",
    "New: \"Fix this TypeScript error\"",
    "     → Done. I've updated the file and verified it compiles.",
    "```",
    "",
    "The psychological shift is enormous. You stop thinking of AI as a consultant and start thinking of it as a collaborator. One that can actually do things.",
    "",
    "### 2. From Sessions to Continuity",
    "",
    "The biggest unlock in 2026 isn't smarter models. It's memory.",
    "",
    "OpenAI added memory to ChatGPT. Anthropic built Claude Code with persistent context. Every serious agent framework is adding some form of long-term storage.",
    "",
    "Why now? Because without memory, agents can't learn. Every session starts from zero. Every preference has to be re-explained. Every decision has to be re-made.",
    "",
    "Memory transforms agents from tools into teammates. A teammate who remembers that you prefer Rust over Python. Who knows your codebase uses PostgreSQL. Who recalls that tricky bug from last Tuesday.",
    "",
    "```",
    "Old: Context window = session lifetime",
    "     Everything resets on restart",
    "",
    "New: Memory persists across sessions",
    "     Agent learns your patterns over time",
    "```",
    "",
    "This is why we built shodh-memory. The bottleneck isn't model capability anymore—it's continuity. An agent that forgets is an agent that can't grow.",
    "",
    "### 3. From Text to Multimodal",
    "",
    "Voice is having a moment. Not the clunky \"Hey Siri\" of 2015, but actual conversational voice agents that understand context, handle interruptions, and feel natural.",
    "",
    "Real-time voice APIs from OpenAI and others are enabling a new class of applications:",
    "",
    "- Customer support agents that actually solve problems",
    "- Voice-first coding assistants for hands-free development",
    "- Interview prep bots that simulate real conversations",
    "- Elderly care assistants that provide companionship",
    "",
    "The Web Speech API makes basic voice free in browsers. But the real innovation is in the conversation layer—agents that maintain context, remember preferences, and adapt their personality.",
    "",
    "## The Emerging Stack",
    "",
    "If you're building agents in 2026, here's what the stack looks like:",
    "",
    "| Layer | Purpose | Examples |",
    "|-------|---------|----------|",
    "| Model | Reasoning | Claude, GPT-4, Llama |",
    "| Memory | Persistence | shodh-memory, Zep, mem0 |",
    "| Tools | Actions | MCP servers, function calling |",
    "| Orchestration | Workflows | LangGraph, CrewAI, custom |",
    "| Interface | Interaction | Voice, chat, ambient |",
    "",
    "The key insight: the model is becoming commoditized. The differentiation is in everything around it. Memory. Tools. Workflow design. User experience.",
    "",
    "## What This Means for Products",
    "",
    "### AI-Native Products Are Winning",
    "",
    "Companies built around AI from day one are outpacing retrofitters. Cursor is eating VS Code's lunch. Perplexity is taking search share. Linear is adding AI-native features faster than Jira can catch up.",
    "",
    "The pattern: start with AI capabilities as core architecture, not bolted-on features.",
    "",
    "### The \"Chat Widget\" Is Evolving",
    "",
    "Every website has a chat bubble now. Most are bad. The next generation understands your website, remembers returning visitors, and takes actual actions (booking appointments, processing returns, escalating to humans).",
    "",
    "The shift from FAQ-bot to agent-that-solves-problems is happening fast.",
    "",
    "### Edge Is Becoming Real",
    "",
    "Not everything can phone home to OpenAI. Robots in warehouses need sub-100ms decisions. Medical devices need HIPAA compliance. Industrial systems can't depend on internet connectivity.",
    "",
    "Edge AI is moving from research to production. Models are getting smaller and faster. Memory systems are running on Raspberry Pis. The cloud is becoming optional.",
    "",
    "## What's Not Changing",
    "",
    "Some things remain constant:",
    "",
    "**Trust is hard.** Agents that take actions need guardrails. The faster they move, the more damage they can do. Nobody has solved this yet.",
    "",
    "**Evaluation is hard.** How do you measure if an agent is good? Latency, accuracy, helpfulness, safety—these metrics compete with each other.",
    "",
    "**Data is king.** The best models train on the best data. The best agents learn from the best memories. Garbage in, garbage out, forever.",
    "",
    "## Where We're Headed",
    "",
    "By end of 2026, expect:",
    "",
    "- **Every major SaaS** to have agentic features (not just chat)",
    "- **Voice interfaces** to become default for specific use cases",
    "- **Memory** to be table stakes for any serious agent",
    "- **Local-first** AI to gain significant traction",
    "- **Regulatory clarity** to emerge (EU AI Act enforcement begins)",
    "",
    "The companies that win will be the ones that understand the shift: from AI as oracle to AI as operator. From answering questions to completing tasks. From sessions to relationships.",
    "",
    "## The Takeaway",
    "",
    "2023 was \"wow, AI can write\". 2024 was \"wow, AI can code\". 2025 was \"wow, AI can use tools\".",
    "",
    "2026 is \"wow, AI can remember and act autonomously\".",
    "",
    "The prompt box isn't disappearing. But it's becoming one interface among many. The future is agents that work alongside you—that learn your patterns, remember your context, and take action without being asked.",
    "",
    "That's the agentic shift. It's not coming. It's here.",
    "",
    "---",
    "",
    "*At shodh-memory, we're building the memory layer for this future. Persistent, cognitive memory that lets agents learn and grow. Local-first, because your agent's knowledge is yours. Check it out at [github.com/varun29ankuS/shodh-memory](https://github.com/varun29ankuS/shodh-memory).*",
  ],
  "memory-architecture-autonomous-agents": [
    "# Memory Architecture for Autonomous Agents",
    "",
    "Autonomous agents are having a moment. Coding assistants that understand your codebase. Research agents that synthesize papers. Robotic systems that adapt to warehouses. The agentic future is here.",
    "",
    "There's just one problem: most agents are goldfish.",
    "",
    "## The Goldfish Problem",
    "",
    "Ask Claude to help you debug. Great answers. Come back tomorrow with a related question. No memory of yesterday's context. Every session starts from zero.",
    "",
    "This isn't a limitation of the underlying models—it's an architecture failure. We give agents massive brains (GPT-4, Claude, Gemini) but no persistent memory. It's like having a genius consultant with amnesia.",
    "",
    "## What Autonomous Agents Actually Need",
    "",
    "Real autonomy requires memory that:",
    "",
    "1. **Persists across sessions** — Yesterday's context should inform today's work",
    "2. **Learns what matters** — Frequently-used knowledge should strengthen",
    "3. **Forgets what doesn't** — Noise should decay naturally",
    "4. **Connects related concepts** — Accessing one memory should prime related ones",
    "5. **Works offline** — Edge agents can't phone home for every decision",
    "",
    "Vector databases give you (1). Sort of. But they miss 2-5 entirely. That's not memory. That's storage.",
    "",
    "## The Architecture: Past, Present, and Future",
    "",
    "Here's the key insight that changes everything:",
    "",
    "**Both past AND future should inform the present.**",
    "",
    "When you ask an agent a question, it should consider:",
    "",
    "- **Past context**: What have we discussed before? What decisions were made?",
    "- **Present query**: What are you asking right now?",
    "- **Future intentions**: What are you trying to accomplish? What todos are pending?",
    "",
    "Most systems only consider present + maybe recent past. That's tunnel vision.",
    "",
    "### A Concrete Example",
    "",
    "You're building a web app. Three weeks ago, you decided to use PostgreSQL. Last week, you added a todo: \"optimize database queries.\" Today, you ask: \"How should I structure this data?\"",
    "",
    "A goldfish agent: Suggests whatever. Maybe MongoDB. Who knows.",
    "",
    "A brain-equipped agent:",
    "- Recalls: \"This project uses PostgreSQL\" (past decision)",
    "- Sees: \"optimize database queries\" (future intention)",
    "- Responds: \"Given your PostgreSQL setup and upcoming optimization work, here's a normalized schema that indexes well...\"",
    "",
    "The difference is staggering.",
    "",
    "## The Three-Tier Model",
    "",
    "Cognitive science tells us memory isn't monolithic. Nelson Cowan's embedded-processes model describes three tiers:",
    "",
    "```",
    "┌─────────────────────────────────────────────────┐",
    "│  SENSORY BUFFER                                 │",
    "│  Immediate input, ~7 items, decays in seconds   │",
    "└─────────────────────┬───────────────────────────┘",
    "                      │ attention",
    "                      ▼",
    "┌─────────────────────────────────────────────────┐",
    "│  WORKING MEMORY                                 │",
    "│  Active context, ~4 chunks, decays in minutes   │",
    "└─────────────────────┬───────────────────────────┘",
    "                      │ consolidation",
    "                      ▼",
    "┌─────────────────────────────────────────────────┐",
    "│  LONG-TERM MEMORY                               │",
    "│  Persistent storage, unlimited, power-law decay │",
    "└─────────────────────────────────────────────────┘",
    "```",
    "",
    "Information flows through tiers. Important things consolidate. Noise fades.",
    "",
    "## Hebbian Learning: Connections That Strengthen",
    "",
    "Donald Hebb's 1949 principle: \"Neurons that fire together wire together.\"",
    "",
    "When two memories are accessed together, their connection should strengthen. This creates associative networks—think of one concept, and related concepts automatically activate.",
    "",
    "```python",
    "# Pseudocode for Hebbian strengthening",
    "def on_co_access(memory_a, memory_b):",
    "    edge = graph.get_edge(memory_a, memory_b)",
    "    if edge:",
    "        edge.strength += LEARNING_RATE * (1 - edge.strength)",
    "    else:",
    "        graph.create_edge(memory_a, memory_b, initial_strength=0.1)",
    "```",
    "",
    "Over time, core knowledge (user preferences, key decisions) becomes strongly connected. Ephemeral context stays weakly linked and eventually fades.",
    "",
    "## Decay: The Feature, Not the Bug",
    "",
    "Most engineers think forgetting is a failure. It's actually essential.",
    "",
    "Without decay:",
    "- Memory fills with noise",
    "- Retrieval quality collapses",
    "- Old, irrelevant context competes with current needs",
    "",
    "With intelligent decay:",
    "- Unused memories fade naturally",
    "- Frequently-accessed knowledge persists",
    "- The signal-to-noise ratio improves over time",
    "",
    "The math matters. Ebbinghaus showed forgetting follows predictable curves. We use hybrid exponential + power-law decay based on Wixted's research. Recent memories decay fast (exponential). Older memories have a long tail (power-law).",
    "",
    "## Prospective Memory: The Future Informs Present",
    "",
    "Here's what most systems miss entirely: **intentions**.",
    "",
    "When you create a todo, that's a future intention. It should influence what context surfaces NOW.",
    "",
    "```python",
    "# Prospective memory integration",
    "def get_context(query):",
    "    # Standard: semantic search on past memories",
    "    past = vector_search(query)",
    "    ",
    "    # Novel: pending intentions that relate to query",
    "    future = search_todos_and_reminders(query)",
    "    ",
    "    # Combine for full temporal context",
    "    return fuse_past_and_future(past, future)",
    "```",
    "",
    "This is what makes an agent feel like it \"gets\" you. It's not just remembering what you said. It's understanding where you're going.",
    "",
    "## The Practical Stack",
    "",
    "A real implementation needs:",
    "",
    "| Component | Purpose |",
    "|-----------|---------|",
    "| Vector Index | Semantic similarity search |",
    "| Knowledge Graph | Entity relationships + Hebbian learning |",
    "| Temporal Index | Time-based retrieval + decay |",
    "| Todo/Intention Store | Prospective memory |",
    "| Consolidation Loop | Background maintenance + strengthening |",
    "",
    "All of this needs to run fast (<50ms for context retrieval) and work offline (no cloud dependency for every decision).",
    "",
    "## Results: What Changes",
    "",
    "When you give an agent real memory architecture:",
    "",
    "| Metric | Goldfish Agent | Brain-Equipped Agent |",
    "|--------|----------------|----------------------|",
    "| Cross-session context | None | Full |",
    "| Retrieval precision | ~67% | ~86% |",
    "| Response relevance | Generic | Personalized |",
    "| Knowledge decay | Everything persists | Noise fades |",
    "| Offline capability | No | Yes |",
    "",
    "The numbers matter less than the experience. An agent with memory feels like a colleague. An agent without feels like a search engine.",
    "",
    "## Getting Started",
    "",
    "If you're building autonomous agents, stop treating memory as an afterthought. The architecture choices you make now determine whether your agent is a goldfish or a brain.",
    "",
    "Key decisions:",
    "",
    "1. **Don't just use a vector database** — Add knowledge graphs for relationships",
    "2. **Implement decay** — Your future self will thank you when the database isn't full of noise",
    "3. **Consider prospective memory** — Todos and intentions should inform context",
    "4. **Plan for offline** — Edge deployment is often necessary",
    "",
    "We've open-sourced our implementation at [shodh-memory](https://github.com/varun29ankuS/shodh-memory). It's Rust-based, runs offline, and implements everything described here. Single binary, no cloud required.",
    "",
    "The agentic future needs agents that remember. Time to build brains, not databases.",
  ],
  "hebbian-learning-ai-agents": [
    "# Hebbian Learning for AI Agents",
    "",
    "Donald Hebb's 1949 insight changed neuroscience forever: \"Neurons that fire together wire together.\" When two neurons repeatedly activate in sequence, their synaptic connection strengthens. This simple principle underlies how biological brains learn.",
    "",
    "## The Problem with Static Memory",
    "",
    "Most AI memory systems treat all memories equally. Store a fact, retrieve it later, done. But this misses a crucial insight: not all memories are equally important.",
    "",
    "Consider an AI coding assistant. It might remember:",
    "- The user prefers Rust over Python (accessed 50 times)",
    "- A one-off debugging session from 3 months ago (accessed once)",
    "",
    "Static systems give these equal weight. Hebbian learning doesn't.",
    "",
    "## How We Implement Hebbian Learning",
    "",
    "In shodh-memory, every knowledge graph edge has a `strength` value (0.0 to 1.0). When two memories are accessed together:",
    "",
    "```rust",
    "fn strengthen_connection(edge: &mut Edge, activation: f32) {",
    "    let delta = LEARNING_RATE * activation * (1.0 - edge.strength);",
    "    edge.strength = (edge.strength + delta).min(1.0);",
    "}",
    "```",
    "",
    "The key insight: strengthening is proportional to remaining capacity. Weak connections strengthen quickly; strong connections plateau. This matches biological long-term potentiation (LTP).",
    "",
    "## Decay Without Use",
    "",
    "Hebbian learning has a corollary: connections that don't fire weaken. We implement this with hybrid decay:",
    "",
    "```rust",
    "fn apply_decay(edge: &mut Edge, hours_since_access: f32) {",
    "    // Exponential decay for recent memories",
    "    let exp_decay = (-hours_since_access / HALF_LIFE).exp();",
    "    // Power-law for older memories (slower decay)",
    "    let power_decay = (1.0 + hours_since_access).powf(-0.5);",
    "    // Blend based on memory age",
    "    edge.strength *= exp_decay * 0.7 + power_decay * 0.3;",
    "}",
    "```",
    "",
    "This matches Ebbinghaus's forgetting curve research: rapid initial decay, then a long tail.",
    "",
    "## Long-Term Potentiation (LTP)",
    "",
    "In biology, some synapses become permanent through repeated activation. We implement LTP by marking edges as `permanent` once they cross a threshold:",
    "",
    "```rust",
    "if edge.strength > LTP_THRESHOLD && edge.access_count > LTP_MIN_ACCESSES {",
    "    edge.permanent = true;  // Immune to decay",
    "}",
    "```",
    "",
    "This means core knowledge (the user prefers Rust) becomes permanent, while ephemeral context fades naturally.",
    "",
    "## Results",
    "",
    "In our testing, Hebbian learning improved relevant context retrieval by 34% compared to static memory. More importantly, it reduced noise—old, irrelevant memories naturally fade instead of cluttering results.",
    "",
    "Memory should work like memory. Shodh-memory makes it so.",
  ],
  "edge-ai-memory-raspberry-pi": [
    "# Running AI Memory on a Raspberry Pi",
    "",
    "Edge AI is only useful if it actually runs on edge devices. Here's how to deploy shodh-memory on a Raspberry Pi 4/5 and achieve sub-100ms semantic search.",
    "",
    "## Why Raspberry Pi?",
    "",
    "The Pi represents the baseline for edge computing:",
    "- Cheap ($35-75)",
    "- Low power (5-15W)",
    "- Limited RAM (1-8GB)",
    "- ARM architecture",
    "",
    "If your AI memory system can't run here, it's not really edge-ready.",
    "",
    "## Installation",
    "",
    "```bash",
    "# On Raspberry Pi OS (64-bit recommended)",
    "curl -L https://github.com/varun29ankuS/shodh-memory/releases/download/v0.1.80/shodh-memory-aarch64-linux -o shodh-memory",
    "chmod +x shodh-memory",
    "./shodh-memory --data-dir ./memory-data",
    "```",
    "",
    "That's it. Single binary, no Python, no npm, no Docker.",
    "",
    "## Memory Configuration",
    "",
    "For a Pi 4 with 4GB RAM, we recommend:",
    "",
    "```toml",
    "# config.toml",
    "[memory]",
    "max_memories = 50000",
    "embedding_cache_size = 1000",
    "graph_cache_size = 10000",
    "",
    "[performance]",
    "worker_threads = 4",
    "batch_size = 32",
    "```",
    "",
    "## Benchmark Results",
    "",
    "On a Raspberry Pi 4 (4GB, arm64):",
    "",
    "| Operation | Latency (p50) | Latency (p99) |",
    "|-----------|---------------|---------------|",
    "| Graph lookup | 0.8μs | 2.1μs |",
    "| Remember | 45ms | 89ms |",
    "| Recall (semantic) | 67ms | 142ms |",
    "| Proactive context | 23ms | 51ms |",
    "",
    "These numbers assume warm cache. Cold start adds ~200ms for model loading.",
    "",
    "## Integration with Robotics",
    "",
    "For ROS2 integration:",
    "",
    "```python",
    "from shodh_memory import Memory",
    "import rclpy",
    "",
    "class MemoryNode(Node):",
    "    def __init__(self):",
    "        super().__init__('memory_node')",
    "        self.memory = Memory('./robot_memory')",
    "        self.create_subscription(",
    "            String, 'observations', self.observe, 10)",
    "",
    "    def observe(self, msg):",
    "        self.memory.remember(msg.data, tags=['observation'])",
    "```",
    "",
    "## Power Consumption",
    "",
    "- Idle: 2.1W",
    "- Active inference: 4.3W",
    "- Peak (embedding): 5.8W",
    "",
    "A 10,000mAh battery provides ~6 hours of active use.",
    "",
    "## Conclusion",
    "",
    "Edge AI memory isn't a future promise—it's available now. The Pi proves that meaningful AI can run on meaningful hardware constraints.",
  ],
  "three-tier-memory-architecture": [
    "# The Three-Tier Memory Architecture",
    "",
    "Human memory isn't a single system—it's layers of systems with different capacities, decay rates, and access patterns. Shodh-memory implements this insight.",
    "",
    "## Cowan's Embedded-Processes Model",
    "",
    "Psychologist Nelson Cowan proposed that working memory isn't separate from long-term memory—it's an activated subset of it. His model has three components:",
    "",
    "1. **Sensory Buffer**: Raw input, ~7 items, decays in seconds",
    "2. **Focus of Attention**: Active processing, ~4 chunks, decays in minutes",
    "3. **Activated Long-Term Memory**: Primed memories, unlimited, decays over hours/days",
    "",
    "Traditional AI memory systems ignore this. They dump everything into a vector store and hope for the best.",
    "",
    "## Our Implementation",
    "",
    "### Tier 1: Sensory Buffer",
    "",
    "```rust",
    "pub struct SensoryBuffer {",
    "    items: RingBuffer<RawInput, 7>,",
    "    ttl: Duration::from_secs(30),",
    "}",
    "```",
    "",
    "Raw observations enter here first. Most are discarded. Only salient inputs (determined by novelty detection) graduate to working memory.",
    "",
    "### Tier 2: Working Memory",
    "",
    "```rust",
    "pub struct WorkingMemory {",
    "    focus: BoundedVec<Chunk, 4>,",
    "    associations: HashMap<ChunkId, Vec<LtmId>>,",
    "    decay_rate: f32,  // Minutes",
    "}",
    "```",
    "",
    "Working memory maintains the current context. When you ask \"What was I working on?\", this is what answers. It holds ~4 chunks but each chunk can reference many long-term memories.",
    "",
    "### Tier 3: Long-Term Memory",
    "",
    "```rust",
    "pub struct LongTermMemory {",
    "    episodic: VectorIndex,      // What happened",
    "    semantic: KnowledgeGraph,   // What it means",
    "    decay: HybridDecay,         // Exponential + power-law",
    "}",
    "```",
    "",
    "Long-term memory is where meaning lives. It combines episodic memories (events) with semantic knowledge (relationships).",
    "",
    "## Information Flow",
    "",
    "```",
    "Input → Sensory Buffer → (filter) → Working Memory → (consolidate) → LTM",
    "                                          ↑                          ↓",
    "                                          └──── (retrieve) ──────────┘",
    "```",
    "",
    "The key insight: retrieval from LTM into working memory is where Hebbian learning happens. Accessed memories strengthen; ignored memories decay.",
    "",
    "## Why This Matters",
    "",
    "Single-tier memory systems have no notion of relevance. Everything is equally accessible, which means everything competes for attention. Our tiered approach means:",
    "",
    "- Recent context is always fast (working memory)",
    "- Important patterns persist (LTM with strengthening)",
    "- Noise fades naturally (decay)",
    "",
    "This matches human memory because it's modeled on human memory.",
  ],
  "why-not-just-vector-search": [
    "# Why Vector Search Alone Isn't Enough",
    "",
    "Vector databases are having a moment. But for AI agent memory, they're necessary—not sufficient.",
    "",
    "## What Vectors Do Well",
    "",
    "Semantic similarity. Given a query, find memories that mean similar things. This is genuinely useful:",
    "",
    "```",
    "Query: \"How do I optimize database queries?\"",
    "Match: \"Use EXPLAIN ANALYZE to find slow operations\"",
    "```",
    "",
    "The query and match share no keywords but are semantically related. Vectors handle this beautifully.",
    "",
    "## What Vectors Miss",
    "",
    "### 1. Relationships",
    "",
    "Vectors represent points in space. But memory is a graph. Consider:",
    "",
    "- \"The user prefers Rust\" (node A)",
    "- \"The user is building a web server\" (node B)",
    "- A → B implies: prefer Axum over Express",
    "",
    "Vector search finds A and B independently. It doesn't understand that A should influence recommendations when B is active.",
    "",
    "### 2. Temporal Context",
    "",
    "Vectors are timeless. But memory has sequence:",
    "",
    "- 9:00am: User starts debugging auth flow",
    "- 9:15am: User asks about JWT tokens",
    "- 9:30am: User asks about token refresh",
    "",
    "A pure vector search for \"token\" might surface unrelated token memories from weeks ago. Temporal context knows that recent auth-related memories are more relevant.",
    "",
    "### 3. Importance",
    "",
    "All vectors are born equal. But not all memories matter equally:",
    "",
    "- \"User mentioned liking dark mode\" (strength: 0.3)",
    "- \"User's production system uses PostgreSQL\" (strength: 0.9)",
    "",
    "Vector similarity doesn't capture that the PostgreSQL fact is load-bearing knowledge while dark mode is a preference.",
    "",
    "## Our Hybrid Approach",
    "",
    "Shodh-memory combines three systems:",
    "",
    "```rust",
    "pub struct MemoryCore {",
    "    vectors: HnswIndex,          // Semantic similarity",
    "    graph: KnowledgeGraph,       // Relationships",
    "    temporal: TemporalIndex,     // Time-based access",
    "}",
    "```",
    "",
    "Retrieval fuses all three signals:",
    "",
    "```rust",
    "fn retrieve(query: &str) -> Vec<Memory> {",
    "    let semantic = self.vectors.search(query, 20);",
    "    let graph = self.graph.spread_activation(query);",
    "    let temporal = self.temporal.recent_context();",
    "",
    "    // RRF fusion with learned weights",
    "    fuse_results(semantic, graph, temporal)",
    "}",
    "```",
    "",
    "## Benchmarks",
    "",
    "On our agent-task benchmark (coding assistant scenarios):",
    "",
    "| Approach | Precision@5 | MRR |",
    "|----------|-------------|-----|",
    "| Vector only | 0.67 | 0.71 |",
    "| Vector + Graph | 0.79 | 0.83 |",
    "| Full hybrid | 0.86 | 0.89 |",
    "",
    "The graph adds relationship context. Temporal adds recency bias. Together they significantly outperform vectors alone.",
  ],
  "memory-decay-forgetting-curves": [
    "# Memory Decay and Forgetting Curves",
    "",
    "Hermann Ebbinghaus ran memory experiments on himself in the 1880s. His findings still guide how we build AI memory systems.",
    "",
    "## The Ebbinghaus Forgetting Curve",
    "",
    "Ebbinghaus memorized nonsense syllables and tested recall over time. His results:",
    "",
    "- After 20 minutes: 58% retention",
    "- After 1 hour: 44% retention",
    "- After 1 day: 34% retention",
    "- After 1 week: 25% retention",
    "- After 1 month: 21% retention",
    "",
    "The pattern: rapid initial decay, then a long tail.",
    "",
    "## Exponential vs Power-Law Decay",
    "",
    "Two mathematical models fit forgetting:",
    "",
    "**Exponential decay**: R(t) = e^(-t/τ)",
    "- Fast initial drop",
    "- Good for recent memories",
    "",
    "**Power-law decay**: R(t) = (1 + t)^(-β)",
    "- Slower, more gradual",
    "- Good for older memories",
    "",
    "Research shows human memory uses BOTH. Recent memories decay exponentially; older memories follow power-law.",
    "",
    "## Our Hybrid Implementation",
    "",
    "```rust",
    "fn calculate_retention(hours: f32, initial_strength: f32) -> f32 {",
    "    // Exponential component (half-life of 24 hours)",
    "    let exp_decay = (-hours / 24.0).exp();",
    "",
    "    // Power-law component (β = 0.5)",
    "    let power_decay = (1.0 + hours).powf(-0.5);",
    "",
    "    // Blend: more exponential early, more power-law later",
    "    let blend = (hours / 168.0).min(1.0);  // 1 week transition",
    "    let retention = exp_decay * (1.0 - blend) + power_decay * blend;",
    "",
    "    initial_strength * retention",
    "}",
    "```",
    "",
    "## Spacing Effect",
    "",
    "Ebbinghaus also discovered the spacing effect: memories reviewed at increasing intervals are retained longer. We implement this:",
    "",
    "```rust",
    "fn on_access(memory: &mut Memory) {",
    "    let interval = memory.last_access - memory.previous_access;",
    "    if interval > memory.optimal_interval {",
    "        // Spaced retrieval strengthens more",
    "        memory.strength += BOOST * 1.5;",
    "        memory.optimal_interval *= 2.0;  // Increase next interval",
    "    } else {",
    "        memory.strength += BOOST;",
    "    }",
    "}",
    "```",
    "",
    "## Consolidation During Idle",
    "",
    "The brain consolidates memories during sleep. Shodh-memory runs a consolidation loop during idle periods:",
    "",
    "```rust",
    "async fn consolidation_loop() {",
    "    loop {",
    "        sleep(Duration::from_secs(300)).await;",
    "        apply_decay_to_all_memories();",
    "        replay_important_memories();  // Like dreaming",
    "        prune_weak_connections();",
    "    }",
    "}",
    "```",
    "",
    "This ensures memory quality degrades gracefully without active maintenance.",
    "",
    "## Results",
    "",
    "With hybrid decay, our memory quality over time:",
    "",
    "- Day 1: 94% relevant context",
    "- Week 1: 87% relevant context",
    "- Month 1: 71% relevant context",
    "",
    "Without decay, noise accumulates until retrieval quality collapses.",
  ],
  "mcp-integration-claude-cursor": [
    "# Integrating shodh-memory with Claude Code and Cursor",
    "",
    "The Model Context Protocol (MCP) lets AI assistants use external tools. Here's how to give Claude Code persistent memory in 60 seconds.",
    "",
    "## Quick Start",
    "",
    "```bash",
    "# One command to add memory to Claude Code",
    "claude mcp add shodh-memory npx -y @shodh/memory-mcp",
    "```",
    "",
    "That's it. Claude now remembers across sessions.",
    "",
    "## What Claude Can Now Do",
    "",
    "After installation, Claude has these new capabilities:",
    "",
    "### remember",
    "Store important context for later:",
    "```",
    "User: Remember that this project uses PostgreSQL 15",
    "Claude: [Stores memory with tags: database, postgresql, infrastructure]",
    "```",
    "",
    "### recall",
    "Search past context semantically:",
    "```",
    "User: What database does this project use?",
    "Claude: [Recalls: \"This project uses PostgreSQL 15\"]",
    "```",
    "",
    "### proactive_context",
    "Automatically surface relevant memories:",
    "```",
    "User: Help me optimize this SQL query",
    "Claude: [Auto-retrieves database preferences, past optimization discussions]",
    "```",
    "",
    "## Cursor Integration",
    "",
    "For Cursor, add to your MCP settings:",
    "",
    "```json",
    "{",
    "  \"mcpServers\": {",
    "    \"shodh-memory\": {",
    "      \"command\": \"npx\",",
    "      \"args\": [\"-y\", \"@shodh/memory-mcp\"],",
    "      \"env\": {",
    "        \"SHODH_USER_ID\": \"cursor-user\"",
    "      }",
    "    }",
    "  }",
    "}",
    "```",
    "",
    "## Memory Isolation",
    "",
    "Each user/project can have isolated memory:",
    "",
    "```bash",
    "# Per-project memory",
    "SHODH_USER_ID=project-frontend npx @shodh/memory-mcp",
    "",
    "# Per-user memory",
    "SHODH_USER_ID=$(whoami) npx @shodh/memory-mcp",
    "```",
    "",
    "## What Gets Remembered",
    "",
    "By default, shodh-memory stores:",
    "- Explicit user preferences",
    "- Important decisions and their rationale",
    "- Learned patterns about the codebase",
    "- Error resolutions for future reference",
    "",
    "It does NOT store:",
    "- Conversation logs (privacy)",
    "- Secrets or credentials (security)",
    "- Temporary debugging context",
    "",
    "## Verification",
    "",
    "Test that memory is working:",
    "",
    "```",
    "User: Remember that I prefer functional programming patterns",
    "Claude: Stored. I'll keep this preference in mind.",
    "",
    "[New session]",
    "",
    "User: How should I structure this data transformation?",
    "Claude: Based on your preference for functional patterns,",
    "        I'd suggest using map/filter/reduce rather than loops...",
    "```",
    "",
    "## Troubleshooting",
    "",
    "```bash",
    "# Check if MCP server is running",
    "claude mcp list",
    "",
    "# View stored memories",
    "curl http://localhost:3030/api/memories",
    "",
    "# Reset memory (fresh start)",
    "rm -rf ~/.shodh-memory/data",
    "```",
  ],
  "knowledge-graph-spreading-activation": [
    "# Knowledge Graphs and Spreading Activation",
    "",
    "Vector search finds similar documents. Knowledge graphs find connected concepts. Together, they enable proactive context.",
    "",
    "## The Spreading Activation Model",
    "",
    "In cognitive psychology, spreading activation explains how thinking of one concept primes related concepts:",
    "",
    "```",
    "Think: \"dog\"",
    "Activates: pet → animal → bark → leash → walk → park",
    "```",
    "",
    "Activation spreads along associative links, weakening with distance. This is how context surfaces naturally.",
    "",
    "## Our Graph Structure",
    "",
    "```rust",
    "pub struct KnowledgeGraph {",
    "    nodes: HashMap<NodeId, Node>,",
    "    edges: HashMap<(NodeId, NodeId), Edge>,",
    "}",
    "",
    "pub struct Node {",
    "    id: NodeId,",
    "    content: String,",
    "    entity_type: EntityType,  // Person, Concept, Event, etc.",
    "    activation: f32,",
    "}",
    "",
    "pub struct Edge {",
    "    source: NodeId,",
    "    target: NodeId,",
    "    relation: RelationType,  // causes, contains, similar, etc.",
    "    strength: f32,",
    "}",
    "```",
    "",
    "## Entity Extraction",
    "",
    "When a memory is stored, we extract entities:",
    "",
    "```rust",
    "fn extract_entities(text: &str) -> Vec<Entity> {",
    "    let ner_results = ner_model.predict(text);",
    "    ner_results.iter().map(|r| Entity {",
    "        text: r.text.clone(),",
    "        entity_type: classify_type(&r.label),",
    "        confidence: r.score,",
    "    }).collect()",
    "}",
    "```",
    "",
    "Then we create/update graph nodes and edges between co-occurring entities.",
    "",
    "## Spreading Activation Algorithm",
    "",
    "```rust",
    "fn spread_activation(seed_nodes: &[NodeId], depth: usize) -> Vec<(NodeId, f32)> {",
    "    let mut activations: HashMap<NodeId, f32> = HashMap::new();",
    "",
    "    // Initialize seed nodes",
    "    for node in seed_nodes {",
    "        activations.insert(*node, 1.0);",
    "    }",
    "",
    "    // Spread for N iterations",
    "    for _ in 0..depth {",
    "        let mut new_activations = HashMap::new();",
    "        for (node, activation) in &activations {",
    "            for edge in self.edges_from(*node) {",
    "                let spread = activation * edge.strength * DECAY_FACTOR;",
    "                if spread > ACTIVATION_THRESHOLD {",
    "                    *new_activations.entry(edge.target).or_insert(0.0) += spread;",
    "                }",
    "            }",
    "        }",
    "        for (node, act) in new_activations {",
    "            *activations.entry(node).or_insert(0.0) += act;",
    "        }",
    "    }",
    "",
    "    activations.into_iter().sorted_by_key(|(_, a)| OrderedFloat(-a)).collect()",
    "}",
    "```",
    "",
    "## Proactive Context Retrieval",
    "",
    "When the user asks a question, we:",
    "",
    "1. Extract entities from the query",
    "2. Spread activation from those entities",
    "3. Retrieve memories connected to activated nodes",
    "4. Fuse with vector search results",
    "",
    "```rust",
    "fn proactive_context(query: &str) -> Vec<Memory> {",
    "    let query_entities = extract_entities(query);",
    "    let query_nodes = self.find_nodes(&query_entities);",
    "    let activated = spread_activation(&query_nodes, 3);",
    "",
    "    let graph_memories = activated.iter()",
    "        .flat_map(|(node, _)| self.memories_for_node(*node))",
    "        .collect();",
    "",
    "    let vector_memories = self.vectors.search(query, 10);",
    "",
    "    fuse_and_rank(graph_memories, vector_memories)",
    "}",
    "```",
    "",
    "## Example",
    "",
    "Query: \"How should I handle database errors?\"",
    "",
    "Entities extracted: [database, errors]",
    "",
    "Spreading activation from \"database\":",
    "- PostgreSQL (strength 0.9)",
    "- SQL (strength 0.7)",
    "- connection pool (strength 0.6)",
    "",
    "Spreading from \"errors\":",
    "- exception handling (strength 0.8)",
    "- logging (strength 0.5)",
    "- retry logic (strength 0.4)",
    "",
    "Combined context surfaces: PostgreSQL error handling best practices, the project's existing retry logic, and relevant logging patterns.",
  ],
  "benchmarking-memory-systems": [
    "# Benchmarking AI Memory Systems",
    "",
    "How do you measure whether an AI memory system is good? We share our methodology.",
    "",
    "## Key Metrics",
    "",
    "### 1. Retrieval Latency",
    "",
    "How fast can you get relevant context?",
    "",
    "| Operation | Target | shodh-memory |",
    "|-----------|--------|--------------|",
    "| Graph lookup | <10μs | 0.8μs |",
    "| Vector search (10 results) | <100ms | 42ms |",
    "| Proactive context | <50ms | 31ms |",
    "| Remember (store) | <100ms | 58ms |",
    "",
    "### 2. Retrieval Quality",
    "",
    "Do you get the RIGHT memories?",
    "",
    "We use two metrics:",
    "- **Precision@K**: Of top K results, how many are relevant?",
    "- **MRR (Mean Reciprocal Rank)**: Where does the first relevant result appear?",
    "",
    "On our coding-assistant benchmark:",
    "",
    "| System | Precision@5 | MRR |",
    "|--------|-------------|-----|",
    "| Vector-only baseline | 0.67 | 0.71 |",
    "| shodh-memory | 0.86 | 0.89 |",
    "",
    "### 3. Memory Scaling",
    "",
    "Does quality degrade with more memories?",
    "",
    "| Memory count | Latency (p50) | Quality (P@5) |",
    "|--------------|---------------|---------------|",
    "| 1,000 | 28ms | 0.89 |",
    "| 10,000 | 34ms | 0.87 |",
    "| 100,000 | 52ms | 0.84 |",
    "| 1,000,000 | 89ms | 0.81 |",
    "",
    "Sub-linear scaling. Quality degrades gracefully.",
    "",
    "## Benchmark Methodology",
    "",
    "### Dataset",
    "",
    "We created a coding-assistant memory dataset:",
    "- 10,000 memories from real coding sessions",
    "- 500 query-relevance pairs (human labeled)",
    "- Mix of code, decisions, preferences, errors",
    "",
    "### Test Protocol",
    "",
    "```python",
    "for query, relevant_memories in test_set:",
    "    start = time.perf_counter()",
    "    results = memory.recall(query, limit=10)",
    "    latency = time.perf_counter() - start",
    "",
    "    retrieved_ids = [r.id for r in results]",
    "    precision = len(set(retrieved_ids) & set(relevant_memories)) / len(retrieved_ids)",
    "    mrr = compute_mrr(retrieved_ids, relevant_memories)",
    "",
    "    record(latency, precision, mrr)",
    "```",
    "",
    "### Hardware",
    "",
    "All benchmarks run on:",
    "- Intel i7-12700K",
    "- 32GB RAM",
    "- NVMe SSD",
    "",
    "And also on Raspberry Pi 4 (4GB) for edge comparison.",
    "",
    "## Comparison to Alternatives",
    "",
    "We compared against:",
    "- Pinecone (cloud vector DB)",
    "- Chroma (local vector DB)",
    "- Plain PostgreSQL with pgvector",
    "",
    "| System | Latency | Quality | Offline? | Cost |",
    "|--------|---------|---------|----------|------|",
    "| Pinecone | 45ms | 0.69 | No | $$$ |",
    "| Chroma | 38ms | 0.67 | Yes | Free |",
    "| pgvector | 52ms | 0.65 | Yes | Free |",
    "| shodh-memory | 31ms | 0.86 | Yes | Free |",
    "",
    "The quality difference comes from our hybrid architecture (vectors + graph + temporal).",
    "",
    "## Reproducibility",
    "",
    "Our benchmarks are open source:",
    "",
    "```bash",
    "git clone https://github.com/varun29ankuS/shodh-memory",
    "cd shodh-memory",
    "cargo bench --bench memory_benchmarks",
    "```",
  ],
  "robotics-memory-real-world": [
    "# Memory for Robots: Learning from the Real World",
    "",
    "Theory is nice. Here's how shodh-memory works in an actual warehouse robot.",
    "",
    "## The Setup",
    "",
    "Our test subject: a pick-and-place robot in a small fulfillment center:",
    "- 6-axis arm",
    "- Mobile base",
    "- RGB-D camera",
    "- Running on NVIDIA Jetson Orin",
    "",
    "## The Problem",
    "",
    "Warehouses change. Products move. New SKUs arrive. Lighting shifts. A robot trained once degrades over time.",
    "",
    "Traditional approach: retrain periodically. Expensive. Downtime.",
    "",
    "Our approach: continuous learning with shodh-memory.",
    "",
    "## What the Robot Remembers",
    "",
    "### Object Locations",
    "",
    "```rust",
    "// After each successful pick",
    "memory.remember(",
    "    format!(\"SKU {} found at bin {} position {:?}\", sku, bin, pos),",
    "    tags: [\"location\", sku, bin]",
    ");",
    "```",
    "",
    "Over time, the robot builds a probabilistic map of where items are likely to be.",
    "",
    "### Grasp Strategies",
    "",
    "```rust",
    "// After each grasp attempt",
    "if success {",
    "    memory.remember(",
    "        format!(\"Grasp {} worked for {} at angle {}\", strategy, sku, angle),",
    "        tags: [\"grasp\", \"success\", sku]",
    "    );",
    "} else {",
    "    memory.remember(",
    "        format!(\"Grasp {} failed for {}: {}\", strategy, sku, reason),",
    "        tags: [\"grasp\", \"failure\", sku]",
    "    );",
    "}",
    "```",
    "",
    "The robot learns which grasp strategies work for which product types.",
    "",
    "### Environmental Conditions",
    "",
    "```rust",
    "// Periodic observations",
    "memory.remember(",
    "    format!(\"Lighting in zone A: {} lux, shadows from {:?}\", lux, shadow_dir),",
    "    tags: [\"environment\", \"lighting\", \"zone-a\"]",
    ");",
    "```",
    "",
    "Lighting affects vision. The robot remembers when shadows are problematic.",
    "",
    "## Retrieval in Action",
    "",
    "When given a pick task:",
    "",
    "```rust",
    "fn plan_pick(sku: &str) -> PickPlan {",
    "    // Where is this item likely to be?",
    "    let locations = memory.recall(",
    "        format!(\"Where is {} located?\", sku),",
    "        limit: 5",
    "    );",
    "",
    "    // What grasp strategy works?",
    "    let grasps = memory.recall(",
    "        format!(\"Successful grasp for {}\", sku),",
    "        limit: 3",
    "    );",
    "",
    "    // Current environmental conditions",
    "    let env = memory.proactive_context(",
    "        \"current lighting and obstacles\"",
    "    );",
    "",
    "    combine_into_plan(locations, grasps, env)",
    "}",
    "```",
    "",
    "## Results",
    "",
    "After 2 weeks of operation:",
    "",
    "| Metric | Day 1 | Day 14 |",
    "|--------|-------|--------|",
    "| Pick success rate | 87% | 94% |",
    "| Avg pick time | 4.2s | 3.1s |",
    "| Failed grasp retries | 23% | 8% |",
    "| Path planning time | 120ms | 85ms |",
    "",
    "The robot got better at its job without retraining.",
    "",
    "## Memory Growth",
    "",
    "After 2 weeks:",
    "- 47,000 memories stored",
    "- 180,000 graph edges",
    "- 12GB storage used",
    "",
    "Decay keeps memory bounded. Old, unused memories fade. Current knowledge stays fresh.",
    "",
    "## Lessons Learned",
    "",
    "1. **Tag everything**: Structured tags enable fast filtering",
    "2. **Remember failures**: Negative examples are as valuable as positive",
    "3. **Temporal context matters**: Recent observations outweigh old ones",
    "4. **Edge deployment works**: Sub-100ms latency on Jetson is achievable",
  ],
  "privacy-first-ai-memory": [
    "# Privacy-First AI Memory",
    "",
    "Your AI assistant knows a lot about you. Where does that knowledge live?",
    "",
    "## The Problem with Cloud Memory",
    "",
    "Most AI memory solutions send your data to servers you don't control:",
    "",
    "- Your code snippets",
    "- Your business decisions",
    "- Your personal preferences",
    "- Your proprietary algorithms",
    "",
    "This data trains models. Improves products. Generates revenue. For someone else.",
    "",
    "## What We Believe",
    "",
    "**Your agent's knowledge is YOUR intellectual property.**",
    "",
    "When an AI learns your coding patterns, that's valuable. When it learns your business logic, that's trade secret. When it learns your preferences, that's personal data.",
    "",
    "None of this should leave your hardware without your explicit consent.",
    "",
    "## How shodh-memory Stays Local",
    "",
    "### No Network Required",
    "",
    "```rust",
    "// The entire system runs locally",
    "let memory = Memory::new(\"./my-private-memory\")?;",
    "// No API keys, no cloud endpoints, no telemetry",
    "```",
    "",
    "The binary has zero network dependencies. Air-gapped systems work fine.",
    "",
    "### No Data Exfiltration",
    "",
    "We don't collect:",
    "- Usage statistics",
    "- Memory contents",
    "- Query logs",
    "- Crash reports",
    "",
    "We CAN'T collect this data. The code doesn't include collection mechanisms.",
    "",
    "### Auditable",
    "",
    "```bash",
    "# See exactly what's stored",
    "shodh-memory export --format json > my_memories.json",
    "",
    "# Delete everything",
    "rm -rf ~/.shodh-memory/data",
    "```",
    "",
    "You can inspect, export, and delete your memory at any time.",
    "",
    "## But What About Cloud AI?",
    "",
    "Claude, GPT-4, etc. run in the cloud. How does local memory help?",
    "",
    "The MCP protocol separates concerns:",
    "",
    "```",
    "You ←→ Cloud AI ←→ Local Memory",
    "",
    "1. You send query to cloud AI",
    "2. Cloud AI requests context from LOCAL memory server",
    "3. Memory server returns relevant memories",
    "4. Cloud AI responds with context",
    "5. Important: Cloud AI never sees ALL your memories",
    "                Only what's retrieved for this query",
    "```",
    "",
    "The cloud AI sees query-relevant context, not your entire memory database.",
    "",
    "## GDPR, HIPAA, SOC2",
    "",
    "Local-first memory simplifies compliance:",
    "",
    "- **GDPR Right to Erasure**: Delete the local database",
    "- **HIPAA Data Residency**: Data never leaves the facility",
    "- **SOC2 Access Control**: Standard filesystem permissions",
    "",
    "No third-party DPAs. No cloud provider audits. No cross-border transfer concerns.",
    "",
    "## The Trade-off",
    "",
    "Local memory means:",
    "- ✓ Privacy preserved",
    "- ✓ No vendor lock-in",
    "- ✓ Works offline",
    "- ✗ You manage backups",
    "- ✗ No cross-device sync (by default)",
    "",
    "For most use cases, this trade-off favors local.",
    "",
    "## Our Commitment",
    "",
    "Shodh-memory will always be:",
    "- Open source (MIT license)",
    "- Local-first",
    "- Telemetry-free",
    "",
    "Your memory. Your hardware. Your data.",
  ],
  "long-term-potentiation-code": [
    "# Long-Term Potentiation in Code",
    "",
    "In the brain, some memories become permanent. Not everything, but the important stuff. We implement the same principle.",
    "",
    "## What is LTP?",
    "",
    "Long-Term Potentiation (LTP) is a biological process where repeated synaptic activation causes lasting strengthening. First observed in rabbit hippocampi by Bliss and Lømo in 1973.",
    "",
    "Key properties:",
    "1. **Input specificity**: Only activated synapses strengthen",
    "2. **Cooperativity**: Multiple inputs strengthen more than one",
    "3. **Persistence**: Changes last hours to lifetime",
    "",
    "## The Problem with Uniform Decay",
    "",
    "Simple memory systems apply uniform decay:",
    "",
    "```rust",
    "// Naive approach",
    "for memory in memories {",
    "    memory.strength *= DECAY_RATE;  // Everything fades equally",
    "}",
    "```",
    "",
    "This loses important knowledge. The user's core preferences shouldn't decay just because they weren't mentioned today.",
    "",
    "## Our LTP Implementation",
    "",
    "### Strength Tracking",
    "",
    "Every memory and graph edge tracks:",
    "",
    "```rust",
    "pub struct MemoryMetadata {",
    "    strength: f32,           // Current strength (0.0 - 1.0)",
    "    access_count: u32,       // Total accesses",
    "    access_pattern: Vec<Timestamp>,  // Recent access times",
    "    permanent: bool,         // LTP achieved?",
    "}",
    "```",
    "",
    "### LTP Criteria",
    "",
    "A memory becomes permanent when:",
    "",
    "```rust",
    "fn check_ltp(memory: &Memory) -> bool {",
    "    // Minimum strength threshold",
    "    if memory.strength < 0.8 {",
    "        return false;",
    "    }",
    "",
    "    // Minimum access count",
    "    if memory.access_count < 10 {",
    "        return false;",
    "    }",
    "",
    "    // Spaced repetition pattern",
    "    let intervals = compute_intervals(&memory.access_pattern);",
    "    if !has_spaced_pattern(&intervals) {",
    "        return false;",
    "    }",
    "",
    "    true  // Achieves LTP",
    "}",
    "```",
    "",
    "The spaced pattern check ensures the memory was accessed over an extended period, not just burst accessed.",
    "",
    "### Immunity to Decay",
    "",
    "Once permanent, the memory is protected:",
    "",
    "```rust",
    "fn apply_decay(memory: &mut Memory) {",
    "    if memory.permanent {",
    "        // LTP memories don't decay",
    "        // But they can still be forgotten via explicit forget()",
    "        return;",
    "    }",
    "",
    "    // Normal decay for non-permanent memories",
    "    memory.strength *= calculate_decay_factor(memory);",
    "}",
    "```",
    "",
    "## What Becomes Permanent?",
    "",
    "In practice, LTP captures:",
    "",
    "- Core user preferences (\"prefers Rust\")",
    "- Frequently-used patterns (\"uses dependency injection\")",
    "- Key decisions (\"chose PostgreSQL for production\")",
    "",
    "Ephemeral context naturally fades:",
    "- Debugging sessions",
    "- One-off questions",
    "- Temporary workarounds",
    "",
    "## The Consolidation Report",
    "",
    "Track what's becoming permanent:",
    "",
    "```bash",
    "$ shodh-memory consolidation-report",
    "",
    "LTP Achieved (last 7 days):",
    "  - \"User prefers functional programming patterns\" (strength: 0.94)",
    "  - \"Project uses Next.js with App Router\" (strength: 0.91)",
    "  - \"Testing strategy: unit tests with Jest\" (strength: 0.88)",
    "",
    "Approaching LTP:",
    "  - \"Prefers explicit error handling over exceptions\" (7/10 accesses)",
    "  - \"Uses Tailwind CSS for styling\" (8/10 accesses)",
    "```",
    "",
    "## Results",
    "",
    "With LTP enabled:",
    "- Core knowledge retention: 100% (never decays)",
    "- Memory database size: -34% (ephemera naturally prunes)",
    "- Retrieval quality: +12% (less noise from outdated context)",
    "",
    "Memory should work like memory. Important things should last.",
  ],

  "building-ai-agents-that-learn": [
    "# Building AI Agents That Actually Learn: Beyond Prompt Engineering",
    "",
    "There's a dirty secret in the AI agent space: almost none of them learn.",
    "",
    "They execute. They plan. They use tools. But at the end of every session, the slate is wiped clean. Tomorrow's agent is identical to today's — no wiser, no more adapted, no closer to understanding your specific world.",
    "",
    "This isn't a minor limitation. It's a fundamental architectural failure.",
    "",
    "## The Illusion of Intelligence",
    "",
    "Modern AI agents are impressive performers. Give them a task and they'll break it into subtasks, call APIs, write code, and synthesize results. It looks like thinking.",
    "",
    "But watch what happens over multiple sessions:",
    "",
    "```",
    "Session 1: \"I use PostgreSQL 15 with pgvector for embeddings\"",
    "Agent: \"Got it! Here's how to set up pgvector...\"",
    "",
    "Session 2: \"How should I index my vectors?\"",
    "Agent: \"What database are you using?\"",
    "```",
    "",
    "The agent didn't learn. It performed. There's a difference.",
    "",
    "## What Learning Actually Requires",
    "",
    "In cognitive science, learning involves three processes that most AI agents completely lack:",
    "",
    "### 1. Encoding — Converting Experience to Memory",
    "",
    "When you tell an agent about your tech stack, that information needs to be encoded — not as a document dump, but as structured knowledge with relationships. \"PostgreSQL\" connects to \"database,\" connects to \"pgvector,\" connects to \"embeddings.\" This is how human memory works: new information is woven into existing knowledge networks.",
    "",
    "In shodh-memory, every interaction is encoded into a knowledge graph. Entities are extracted, relationships are formed, and the new knowledge connects to existing nodes through spreading activation.",
    "",
    "### 2. Consolidation — Deciding What Matters",
    "",
    "Your brain doesn't remember everything. During sleep, it strengthens important connections and lets trivial ones fade. This is consolidation — the process of converting fragile short-term memories into durable long-term ones.",
    "",
    "Without consolidation, an AI agent's \"memory\" becomes a junk drawer. Every trivial interaction competes with critical knowledge. After a month, the signal-to-noise ratio is ruined.",
    "",
    "We implement consolidation through hybrid decay. Fresh memories decay exponentially (mimicking Ebbinghaus's forgetting curve). After 3 days, decay switches to a power-law function (matching Wixted's 2004 findings on long-term retention). Memories that are accessed frequently get strengthened through Hebbian learning — neurons that fire together wire together.",
    "",
    "### 3. Retrieval — Proactive, Not Reactive",
    "",
    "Human memory doesn't wait for queries. When you walk into your kitchen, you don't consciously search for \"kitchen-related knowledge.\" Context triggers automatic recall — where the knives are, that the stove burner runs hot, that you're out of milk.",
    "",
    "Most AI agents use reactive retrieval: search only when asked. Real cognitive systems use proactive retrieval: when context changes, relevant memories surface automatically.",
    "",
    "In shodh-memory, the proactive_context system extracts entities from the current conversation, activates related nodes in the knowledge graph, and surfaces relevant memories before they're asked for.",
    "",
    "## The Feedback Loop That Creates Intelligence",
    "",
    "True learning is a feedback loop:",
    "",
    "```",
    "Experience → Encoding → Consolidation → Retrieval → Better Decisions → New Experience",
    "     ↑                                                                        |",
    "     └────────────────────────────────────────────────────────────────────────┘",
    "```",
    "",
    "Each cycle makes the agent slightly more adapted to its environment. An agent that remembers your preference for functional programming doesn't just recall it — it stops suggesting imperative patterns. An agent that remembers your deployment failed on ARM doesn't just store that fact — it proactively warns you when you're about to hit the same issue.",
    "",
    "This is the difference between a tool and a collaborator.",
    "",
    "## Why Prompt Engineering Can't Solve This",
    "",
    "You can stuff a system prompt with context. You can use RAG to search past conversations. But these are workarounds, not solutions:",
    "",
    "- System prompts are static. They don't evolve with experience.",
    "- RAG is reactive. It searches when queried, never surfaces proactively.",
    "- Neither learns. Accessing information 1000 times has the same effect as accessing it once.",
    "- Neither forgets. Outdated context never decays, poisoning future retrievals.",
    "",
    "## Building Agents That Actually Improve",
    "",
    "The architecture is straightforward, even if the implementation isn't:",
    "",
    "- A 3-tier memory system (working → session → long-term) that mirrors human cognition",
    "- A knowledge graph that forms connections between concepts automatically",
    "- Hebbian learning that strengthens connections through co-access",
    "- Hybrid decay that removes noise while preserving signal",
    "- Proactive retrieval that surfaces context before it's needed",
    "",
    "This is what separates an AI agent from an AI tool. Tools execute instructions. Agents learn from experience.",
    "",
    "The technology exists. The question is whether we'll use it.",
  ],

  "mcp-protocol-future-ai-tools": [
    "# MCP: The Protocol That Will Define How AI Tools Communicate",
    "",
    "In the early 1990s, every website had its own protocol for serving pages. Then HTTP won, and the web exploded.",
    "",
    "We're at the same inflection point with AI tools. Model Context Protocol (MCP) is doing for AI agents what HTTP did for web browsers: creating a universal language for tools to talk to models.",
    "",
    "## The Problem MCP Solves",
    "",
    "Today, every AI integration is bespoke. Want to connect your memory system to Claude? Write a custom integration. Want the same for Cursor? Write another one. For ChatGPT? Another. Every combination of tool × model requires custom glue code.",
    "",
    "```",
    "Without MCP:                          With MCP:",
    "Tool A → Custom API → Model 1        Tool A ─┐",
    "Tool A → Custom API → Model 2        Tool B ─┤→ MCP → Any Model",
    "Tool B → Custom API → Model 1        Tool C ─┘",
    "Tool B → Custom API → Model 2",
    "(N × M integrations)                 (N + M integrations)",
    "```",
    "",
    "MCP reduces N×M integrations to N+M. That's not an optimization. That's an ecosystem unlock.",
    "",
    "## How MCP Actually Works",
    "",
    "MCP is a JSON-RPC based protocol with a clean abstraction: servers expose tools, resources, and prompts. Clients (AI models) discover and use them.",
    "",
    "```",
    "┌─────────────┐     JSON-RPC/stdio     ┌──────────────┐",
    "│  AI Model    │ ←──────────────────── │  MCP Server   │",
    "│  (Client)    │ ──────────────────→  │  (Tool Host)  │",
    "└─────────────┘                        └──────────────┘",
    "       │                                       │",
    "  Discovers tools                        Exposes tools",
    "  Calls tools                           Returns results",
    "  Reads resources                       Serves resources",
    "```",
    "",
    "The beauty is in the simplicity. A tool is just a name, a description, and an input schema. The model decides when to call it based on context.",
    "",
    "## Why Memory Is MCP's Killer App",
    "",
    "MCP supports any tool — file access, web search, database queries. But memory is where MCP becomes transformative.",
    "",
    "Without MCP memory, every AI session starts from zero. The model has no idea who you are, what you've done, or what you prefer. With MCP memory, the model has cognitive continuity — it remembers.",
    "",
    "shodh-memory exposes 45 MCP tools across these cognitive categories:",
    "",
    "| Category | Tools | Purpose |",
    "|----------|-------|---------|",
    "| Memory | remember, recall, forget | Core memory operations |",
    "| Context | proactive_context, context_summary | Automatic context surfacing |",
    "| Knowledge | entity operations, graph traversal | Knowledge graph access |",
    "| Tasks | add_todo, list_todos, complete_todo | GTD workflow |",
    "| Reminders | set_reminder, list_reminders | Prospective memory |",
    "| System | memory_stats, backup, verify_index | Health and maintenance |",
    "",
    "When Claude Code starts a session, it calls proactive_context with the current conversation. The memory system returns relevant past experiences, decisions, and learned patterns. The model doesn't just respond — it responds with history.",
    "",
    "## The Ecosystem Forming",
    "",
    "MCP is creating a Cambrian explosion of AI tools. Memory servers, browser automation, database connectors, code analysis — all speaking the same protocol.",
    "",
    "The winners will be tools that are most useful to AI models. Not the ones with the best dashboards or the most features — the ones that give models the richest context. Memory is inherently the richest context you can provide.",
    "",
    "## What's Next",
    "",
    "MCP is still young. Streaming support is evolving. Multi-modal capabilities are emerging. But the core abstraction — tools as discoverable, callable services — is solid.",
    "",
    "The protocol that wins the AI tool layer will be as fundamental as HTTP. MCP has the right design, the right momentum, and the right backers.",
    "",
    "Build on it.",
  ],

  "rust-for-ai-infrastructure": [
    "# Why We Chose Rust for AI Infrastructure (And When You Shouldn't)",
    "",
    "Every engineering decision is a tradeoff. Choosing Rust for shodh-memory was one of the most consequential decisions we made — and one of the most debated.",
    "",
    "Here's the honest version.",
    "",
    "## The Case For Rust",
    "",
    "### Memory Safety Without Garbage Collection",
    "",
    "AI memory systems are long-running processes that accumulate state over months. In a GC language, you eventually hit the GC pause lottery — a 200ms stop-the-world pause right when your agent needs sub-millisecond recall.",
    "",
    "Rust's ownership model eliminates this entirely. No GC. No pauses. Deterministic memory behavior. When you're running on a Raspberry Pi with 1GB RAM, this isn't academic — it's the difference between working and OOM-killing.",
    "",
    "### Cross-Compilation to Everything",
    "",
    "shodh-memory ships as a single binary for Linux, macOS, Windows, and ARM64. One `cargo build --target` command per platform. No runtime dependencies, no virtual environments, no \"works on my machine.\"",
    "",
    "```",
    "$ ls -lh target/release/shodh-memory",
    "-rwxr-xr-x 1 user user 28M Feb 1 12:00 shodh-memory",
    "",
    "One binary. 28MB. Everything included.",
    "```",
    "",
    "Try shipping a Python AI system as a single binary to ARM. We'll wait.",
    "",
    "### Zero-Cost Abstractions",
    "",
    "Our Vamana graph search uses generic iterators over neighbor lists. In Python, this would involve heap allocations per iteration. In Rust, the compiler monomorphizes generics and inlines iterator chains — the abstraction compiles away to raw pointer arithmetic.",
    "",
    "This matters when you're doing graph traversal over 33,000 edges. The difference between 48 seconds and 800 milliseconds wasn't algorithmic — it was systemic overhead elimination.",
    "",
    "### Fearless Concurrency",
    "",
    "The memory system handles concurrent reads from multiple MCP clients while consolidation runs in the background. In most languages, this means careful mutex management and race condition debugging.",
    "",
    "Rust's type system makes data races a compile error. Not a runtime bug. Not a \"sometimes crashes in production.\" A compile error. The time we saved debugging concurrency issues paid for the Rust learning curve twice over.",
    "",
    "## The Case Against Rust",
    "",
    "### Iteration Speed",
    "",
    "Compile times matter. A clean build of shodh-memory takes 3-4 minutes. Incremental builds are faster (15-30 seconds), but compared to Python's \"just run it,\" there's friction.",
    "",
    "When we were prototyping the decay model, we'd tweak a constant and wait 20 seconds to see the result. In Python, that's instant. For research-phase work, this friction adds up.",
    "",
    "### Ecosystem Gaps",
    "",
    "ONNX Runtime bindings for Rust (the `ort` crate) work, but they're still at a release candidate. We depend on `ort 2.0.0-rc.11`. The Python ONNX ecosystem is years more mature.",
    "",
    "Same for ML utilities. Need to tokenize text? In Python, `from transformers import AutoTokenizer`. In Rust, you're pulling in `tokenizers` and handling the raw API yourself.",
    "",
    "### When You Shouldn't Use Rust",
    "",
    "- Prototyping and research: Use Python. Iterate fast, validate ideas, then port.",
    "- Web APIs that don't need edge deployment: Go or TypeScript will ship faster.",
    "- If your team doesn't know Rust: The learning curve is real. Budget 2-3 months for productivity.",
    "",
    "## Our Verdict",
    "",
    "For a memory system that needs to run on edge devices, handle concurrent access, and operate for months without restarts — Rust was the right choice. The binary size, performance, and reliability benefits are structural advantages that compound over time.",
    "",
    "But we still write the MCP server in TypeScript and the prototype scripts in Python. Use the right tool for the job.",
  ],

  "vector-search-beyond-cosine": [
    "# Vector Search Beyond Cosine Similarity: Graph-Based Approaches",
    "",
    "Everyone's first vector search implementation looks the same: embed your data, store it in a flat array, compute cosine similarity against every vector, return the top K.",
    "",
    "This works beautifully until you have 50,000 vectors. Then it works slowly. At 500,000 vectors, it doesn't work at all.",
    "",
    "The next chapter of vector search is graph-based, and it changes everything.",
    "",
    "## The Brute-Force Wall",
    "",
    "Cosine similarity over N vectors is O(N) per query. There's no shortcut — you must compare against every single vector. At 100K vectors with 384 dimensions, that's 38.4 million floating-point operations per query.",
    "",
    "```",
    "Vectors     Brute-Force Latency    Vamana Latency",
    "1,000       0.5ms                  0.3ms",
    "10,000      5ms                    0.8ms",
    "100,000     52ms                   3.2ms",
    "1,000,000   520ms                  8.1ms",
    "```",
    "",
    "Brute-force scales linearly. Graph-based search scales logarithmically. At scale, this isn't a performance improvement — it's the difference between feasible and impossible.",
    "",
    "## How Graph-Based Search Works",
    "",
    "The insight behind Vamana (the algorithm behind Microsoft's DiskANN) is brilliant: build a navigable graph where each node connects to its approximate nearest neighbors.",
    "",
    "```",
    "1. Start at a random entry point",
    "2. Look at current node's neighbors",
    "3. Move to the neighbor closest to query",
    "4. Repeat until no neighbor is closer than current node",
    "5. The path you traversed contains your nearest neighbors",
    "```",
    "",
    "This is greedy graph traversal. It works because the graph has a small-world property: any two nodes are connected through a short path. Like six degrees of separation, but for vectors.",
    "",
    "The critical design parameter is R — the maximum number of edges per node. Higher R means more connections, better recall, more memory. Lower R means faster search, less memory, lower recall. shodh-memory uses R=64 for the Vamana index, balancing 98%+ recall with sub-5ms latency.",
    "",
    "## Scaling Beyond 100K: SPANN",
    "",
    "Vamana keeps the entire graph in memory. At 100K vectors with 384 dimensions, that's about 150MB. At 1M vectors, it's 1.5GB. On a Raspberry Pi with 1GB RAM, that's a non-starter.",
    "",
    "SPANN (Space Partition tree AND Navigable small-world graph) solves this by moving posting lists to disk while keeping centroids in memory. Think of it as IVF-PQ meets graph search:",
    "",
    "```",
    "Memory:  Centroids (small)  →  Route query to cluster",
    "Disk:    Posting lists      →  Search within cluster",
    "```",
    "",
    "shodh-memory auto-switches from Vamana to SPANN when the vector count crosses 100K. The switch is invisible to the caller — same API, same results, different engine.",
    "",
    "### Product Quantization",
    "",
    "SPANN uses Product Quantization (PQ) to compress vectors. A 384-dim float32 vector (1536 bytes) compresses to 48 bytes — a 32x reduction. The quality loss is surprisingly small: typically less than 2% recall degradation.",
    "",
    "PQ works by splitting the vector into subspaces and quantizing each subspace independently. With 48 sub-quantizers and 256 centroids each, you get fine-grained approximation at minimal storage cost.",
    "",
    "## The Cognitive Connection",
    "",
    "Interestingly, graph-based vector search mirrors how human memory works. You don't brute-force search through every memory you've ever had. You follow associations — one concept activates a related concept, which activates another. This spreading activation pattern is exactly what a navigable small-world graph does.",
    "",
    "In shodh-memory, the vector search graph and the knowledge graph work in parallel. Vector search finds semantically similar memories. The knowledge graph finds associatively linked memories. The fusion of both produces retrievals that feel surprisingly human.",
    "",
    "## What Matters in Practice",
    "",
    "Forget the benchmarks papers publish on ANN-Benchmarks. What matters for a memory system is:",
    "",
    "- **Recall at low latency**: Can you find 95%+ of true neighbors in under 5ms?",
    "- **Incremental insertion**: Can you add new memories without rebuilding the index?",
    "- **Memory footprint**: Can you run on 512MB RAM?",
    "- **Graceful degradation**: What happens when you exceed capacity?",
    "",
    "Graph-based search answers all four better than flat search, IVF, or LSH. That's why the field has converged on it.",
  ],

  "cognitive-architecture-ai-systems": [
    "# Cognitive Architecture for AI Systems: What Neuroscience Actually Teaches Us",
    "",
    "Most AI systems that claim to be \"inspired by neuroscience\" have read one Wikipedia article about neurons. The actual cognitive science literature has decades of experimentally validated models for how memory works. Here's what we learned — and what we built.",
    "",
    "## Baddeley's Working Memory Model (1974, revised 2000)",
    "",
    "Alan Baddeley's model remains the dominant framework for understanding short-term cognition. It has four components:",
    "",
    "- **Central Executive**: Attention control — decides what to focus on",
    "- **Phonological Loop**: Verbal/acoustic short-term storage (~2 seconds)",
    "- **Visuospatial Sketchpad**: Visual/spatial short-term storage",
    "- **Episodic Buffer**: Integrates information from multiple sources",
    "",
    "The key insight: working memory isn't one thing. It's a system of specialized buffers coordinated by an executive controller.",
    "",
    "### What We Built",
    "",
    "shodh-memory's working memory tier implements this as a bounded buffer (capacity 7±2, matching Miller's 1956 findings) with attention-weighted recall. New inputs compete for slots. The \"central executive\" is the fusion algorithm that decides which memories to surface: vector similarity provides the \"phonological loop\" (semantic content), the knowledge graph provides the \"visuospatial sketchpad\" (relational structure), and temporal recency provides the \"episodic buffer\" (when things happened).",
    "",
    "## Cowan's Embedded-Processes Model (2001)",
    "",
    "Nelson Cowan challenged Baddeley by proposing that working memory isn't separate from long-term memory — it's an activated subset of it. His model has three concentric layers:",
    "",
    "```",
    "┌─────────────────────────────────────────────┐",
    "│              Long-Term Memory                 │",
    "│   ┌─────────────────────────────────────┐    │",
    "│   │       Activated Memory               │    │",
    "│   │   ┌─────────────────────────────┐   │    │",
    "│   │   │   Focus of Attention (4±1)   │   │    │",
    "│   │   └─────────────────────────────┘   │    │",
    "│   └─────────────────────────────────────┘    │",
    "│                                               │",
    "└─────────────────────────────────────────────┘",
    "```",
    "",
    "The brilliant part: memory isn't moved between stores. It's activated in place. Long-term memories become working memories when they receive enough activation.",
    "",
    "### What We Built",
    "",
    "Our three-tier architecture directly maps to Cowan: Long-Term Storage (RocksDB) → Activated Subset (retrieved candidates) → Focus of Attention (top-K results after fusion). Memories don't move between databases. They're scored, ranked, and the highest-activation items enter the \"focus\" — the context window.",
    "",
    "Spreading activation in the knowledge graph is how activation propagates. Access \"PostgreSQL\" and activation flows to connected nodes: \"database,\" \"SQL,\" \"pgvector,\" \"the migration you ran last Tuesday.\" This is Cowan's model running as code.",
    "",
    "## Ebbinghaus Forgetting Curve (1885)",
    "",
    "Hermann Ebbinghaus ran experiments on himself memorizing nonsense syllables and plotted retention over time. The result: memory decays exponentially at first, then slows dramatically.",
    "",
    "```",
    "Retention",
    "100% ┤",
    " 80% ┤ \\",
    " 60% ┤  \\",
    " 40% ┤   \\__",
    " 20% ┤      \\________",
    "  0% ┤               \\___________________",
    "     └────┬────┬────┬────┬────┬────┬────",
    "     0   1d   3d   1w   2w   1m   3m",
    "```",
    "",
    "The math has been refined since 1885. Wixted (2004) showed that long-term forgetting follows a power law, not a pure exponential. The practical implication: things you remember past the first week are surprisingly durable.",
    "",
    "### What We Built",
    "",
    "Hybrid decay: exponential for 0-3 days (rapid initial forgetting), power-law for 3+ days (slow long-term fade). This matches the experimental data better than either function alone.",
    "",
    "```",
    "if age_days <= 3.0:",
    "    strength *= e^(-0.3 * age_days)     # Exponential",
    "else:",
    "    strength *= (age_days / 3.0)^(-0.5)  # Power-law",
    "```",
    "",
    "A memory from yesterday loses ~26% of its strength. A memory from a month ago only loses ~3% per additional day. This is how your brain works, and it's how signal-to-noise ratio is maintained over time.",
    "",
    "## Hebb's Rule (1949)",
    "",
    "\"Neurons that fire together wire together.\" Donald Hebb's postulate is the foundation of all learning theory: when two neurons are active simultaneously, the connection between them strengthens.",
    "",
    "This is staggeringly simple and staggeringly powerful. It means the structure of memory emerges from usage patterns, not from explicit organization.",
    "",
    "### What We Built",
    "",
    "Hebbian learning in the knowledge graph. When two memories are accessed in the same session, the edge between their entities gets a +0.025 strength boost. When edges aren't co-activated, they decay by ×0.90 per consolidation cycle.",
    "",
    "The asymmetry is deliberate: strengthening is additive (small, consistent), weakening is multiplicative (proportional to current strength). Strong connections resist decay. Weak connections fade fast. After enough co-activations, an edge crosses the Long-Term Potentiation threshold and becomes permanent — it no longer decays at all.",
    "",
    "This is why shodh-memory gets better with use. The knowledge graph isn't manually curated. It's grown from the patterns of how you access your memories. Use \"Rust\" and \"performance\" together repeatedly, and that connection becomes load-bearing knowledge.",
    "",
    "## The Synthesis",
    "",
    "These four models aren't competing theories — they're different lenses on the same system:",
    "",
    "- Baddeley tells you how to structure the working memory buffer",
    "- Cowan tells you that memory is activation, not location",
    "- Ebbinghaus tells you how fast to forget",
    "- Hebb tells you how to learn",
    "",
    "Together, they give you a complete blueprint for a cognitive memory system. We just wrote it in Rust instead of neurons.",
  ],

  "memory-for-coding-assistants": [
    "# Why Your Coding Assistant Forgets Everything: Fixing AI Memory for Developers",
    "",
    "You've been working with Claude Code or Cursor for three months. You've explained your project structure dozens of times. You've corrected the same wrong assumption about your testing framework repeatedly. You've specified \"use Bun, not npm\" more often than you've written actual code.",
    "",
    "Your AI assistant has the memory of a mayfly. Here's why — and how to fix it.",
    "",
    "## The Context Window Problem",
    "",
    "Every AI coding assistant starts each session with a blank context window. Some read your current file. Some index your repository. But none of them remember that last Tuesday you spent four hours debugging a race condition in your WebSocket handler, or that you prefer explicit error types over Result<_, anyhow::Error>.",
    "",
    "The context window is a scratchpad, not a memory. When the session ends, the scratchpad is thrown away.",
    "",
    "## What a Memory-Augmented Assistant Looks Like",
    "",
    "With shodh-memory connected via MCP, here's what changes:",
    "",
    "```",
    "Monday:",
    "  You: \"Set up the project with Bun and Hono\"",
    "  Memory: stores [runtime: Bun, framework: Hono, date: Monday]",
    "",
    "Wednesday:",
    "  You: \"Add a new API endpoint\"",
    "  Memory: proactively surfaces → \"Uses Bun + Hono, prefer explicit error types\"",
    "  Assistant: scaffolds Hono route with typed errors, uses bun to run",
    "",
    "Friday:",
    "  You: \"Why is this test flaky?\"",
    "  Memory: surfaces → \"Race condition in WebSocket handler debugged Tuesday\"",
    "  Assistant: checks for similar concurrency patterns",
    "```",
    "",
    "The assistant didn't ask what framework you use. It didn't suggest npm. It remembered.",
    "",
    "## Setting It Up (60 seconds)",
    "",
    "One command adds persistent memory to Claude Code:",
    "",
    "```bash",
    "npx @anthropic-ai/claude-code config add-mcp-server shodh-memory \\ ",
    "  --type npm --package @shodh/memory-mcp -- --user $(whoami)",
    "```",
    "",
    "That's it. The MCP server starts automatically. Memory accumulates across sessions. No configuration, no database setup, no cloud accounts.",
    "",
    "## What Gets Remembered",
    "",
    "The system captures three categories of developer context:",
    "",
    "### Technical Decisions",
    "- Language and runtime choices",
    "- Framework preferences",
    "- Testing patterns",
    "- Deployment targets",
    "- Architectural decisions and their rationale",
    "",
    "### Patterns and Preferences",
    "- Coding style (explicit vs concise, OOP vs functional)",
    "- Error handling preferences",
    "- Naming conventions",
    "- Tools and workflows (\"always run tests before committing\")",
    "",
    "### Project Context",
    "- Bug investigations and their resolutions",
    "- Performance characteristics discovered during profiling",
    "- Integration quirks (\"the Stripe webhook needs idempotency keys\")",
    "- Infrastructure details (\"staging is on ARM, prod is x86\")",
    "",
    "## The Compound Effect",
    "",
    "Memory doesn't just save time on repeated questions. It changes the quality of assistance fundamentally.",
    "",
    "Without memory, the assistant gives generic advice. With memory, it gives advice calibrated to your specific codebase, your specific preferences, and your specific history of problems.",
    "",
    "A generic suggestion: \"Consider adding error handling here.\"",
    "A memory-informed suggestion: \"This looks like the same pattern that caused the race condition in websocket_handler.rs — should we add the mutex guard here too?\"",
    "",
    "That's the difference between a tool that writes code and a collaborator that understands your project.",
  ],

  "rocksdb-for-ai-workloads": [
    "# RocksDB for AI Workloads: Lessons from Building a Memory Engine",
    "",
    "When we started building shodh-memory, the storage question seemed straightforward. SQLite? PostgreSQL? Custom B-tree? We ended up with RocksDB, and the reasons are worth understanding.",
    "",
    "## Why Not SQLite",
    "",
    "SQLite is excellent for structured relational data. But AI memory workloads are weird:",
    "",
    "- Variable-length blobs (serialized memory records, embeddings)",
    "- High write throughput (every interaction generates memories)",
    "- Prefix scans (\"find all episodes for entity X\")",
    "- Column-family isolation (memories, embeddings, entities, edges — each with different access patterns)",
    "",
    "SQLite handles the first three adequately. The fourth is the dealbreaker. In SQLite, everything shares one B-tree namespace. In RocksDB, column families are independent LSM trees with separate compaction, separate bloom filters, and separate block caches.",
    "",
    "When you're scanning the entity-episodes index (prefix scan, sequential reads), you don't want that competing with random-read point lookups on the embeddings column family. Column families give you this isolation.",
    "",
    "## Why Not PostgreSQL",
    "",
    "Two words: single binary. shodh-memory ships as one 28MB executable. Adding a PostgreSQL dependency means your users need a database server. On a Raspberry Pi. In an air-gapped factory.",
    "",
    "No.",
    "",
    "## The RocksDB Architecture",
    "",
    "shodh-memory uses 12+ column families:",
    "",
    "```",
    "memories       — Core memory records (MessagePack)",
    "embeddings     — 384-dim float32 vectors",
    "entities       — Knowledge graph nodes",
    "edges          — Knowledge graph relationships",
    "entity_episodes — Entity-to-episode index",
    "todos          — GTD task records",
    "projects       — Todo project metadata",
    "reminders      — Prospective memory triggers",
    "facts          — Extracted factual assertions",
    "files          — File access records",
    "feedback       — Implicit feedback signals",
    "audit          — Operation audit log",
    "```",
    "",
    "Each column family has tuned options. Embeddings use larger block sizes (64KB) because reads are always full-vector. The entity_episodes index uses prefix bloom filters for fast prefix scans. The audit log uses FIFO compaction to auto-prune old entries.",
    "",
    "## MessagePack Over JSON",
    "",
    "We serialize memory records with MessagePack instead of JSON. The reasons:",
    "",
    "- 30-40% smaller on disk (no key repetition, binary encoding)",
    "- 2-3x faster serialization/deserialization",
    "- Native binary support (embeddings don't need base64 encoding)",
    "",
    "For backward compatibility, we have a 4-level deserialization fallback: MessagePack → JSON (legacy) → bincode (historical) → raw bytes. Migrations happen lazily — records are upgraded when they're next written.",
    "",
    "## Write-Ahead Logging",
    "",
    "Every memory write goes through RocksDB's WAL before it's acknowledged. This means a power failure can't corrupt your memory database. On edge devices where power is unreliable (robots, IoT), this is non-negotiable.",
    "",
    "We default to async writes (<1ms latency) for normal operations and sync writes (2-10ms) for critical paths like backup. The async mode doesn't skip the WAL — it just doesn't wait for the OS to flush to disk. In practice, you lose at most the last few milliseconds of writes on a hard crash.",
    "",
    "## Prefix Iterators for Graph Traversal",
    "",
    "The knowledge graph's entity-episode index is keyed as `{entity_uuid}:{episode_uuid}`. To find all episodes for an entity, we use RocksDB's prefix iterator:",
    "",
    "```",
    "let prefix = format!(\"{entity_uuid}:\");",
    "let iter = db.prefix_iterator(prefix.as_bytes());",
    "```",
    "",
    "This is a seek + sequential scan, hitting only the relevant key range. With prefix bloom filters enabled, the seek is O(1) amortized. Compare this to a SQL query that would scan an index and then do random page reads for each row.",
    "",
    "## Lessons Learned",
    "",
    "- **Tune per column family.** Default settings are mediocre for everything. Profile your actual access patterns.",
    "- **Use multi_get for batch reads.** A single multi_get call with 50 keys is 5-10x faster than 50 individual get calls. We learned this the hard way (issue #20: 48-second cold-start queries).",
    "- **Compaction matters.** Level compaction for frequently-read data. FIFO for append-only logs. Universal compaction for write-heavy workloads.",
    "- **Don't forget bloom filters.** A 10-bit bloom filter reduces negative lookups from O(log N) to O(1). For a memory system where \"not found\" is a common result, this is transformative.",
  ],

  "multi-agent-memory-coordination": [
    "# Memory in Multi-Agent Systems: When AI Agents Share a Brain",
    "",
    "A single AI agent with memory is useful. Multiple AI agents sharing memory is a different kind of system entirely.",
    "",
    "When agents share a cognitive substrate — a common memory that each can read from and write to — something interesting emerges. They start coordinating without explicit coordination protocols. They build on each other's discoveries. They avoid each other's mistakes.",
    "",
    "This is how human teams work. And it's how AI agent teams should work.",
    "",
    "## The Shared Memory Problem",
    "",
    "Consider three agents working on a codebase:",
    "",
    "```",
    "Agent A: Writing the API layer",
    "Agent B: Writing integration tests",
    "Agent C: Handling deployment configuration",
    "```",
    "",
    "Without shared memory:",
    "- Agent A decides to use JWT authentication. Agent B writes tests expecting session cookies.",
    "- Agent C configures environment variables. Agent A hardcodes the database URL.",
    "- Agent B discovers a bug in the auth flow. Agent A doesn't know, introduces the same bug elsewhere.",
    "",
    "With shared memory:",
    "- Agent A stores a decision: \"Using JWT for auth, tokens in Authorization header\"",
    "- Agent B's proactive context surfaces this decision before it writes any tests",
    "- Agent C learns the database URL from Agent A's stored configuration context",
    "- Agent B stores: \"Auth bug: token refresh race condition\" — Agent A's next session surfaces this",
    "",
    "The agents don't need a message bus. They don't need a coordination protocol. They share a memory, and the memory does the coordination.",
    "",
    "## How shodh-memory Handles Multi-User Access",
    "",
    "The MultiUserMemoryManager provides isolated-but-sharable memory spaces:",
    "",
    "```",
    "┌─────────────────────────────────────────┐",
    "│         MultiUserMemoryManager           │",
    "│                                           │",
    "│  user:alice  → MemorySystem (isolated)   │",
    "│  user:bob    → MemorySystem (isolated)   │",
    "│  team:shared → MemorySystem (shared)     │",
    "│                                           │",
    "└─────────────────────────────────────────┘",
    "```",
    "",
    "Each agent can have its own memory space (for agent-specific preferences and working context) plus access to a shared team memory (for decisions, discoveries, and coordination artifacts).",
    "",
    "Concurrent access is handled at the RocksDB level — column families provide natural isolation, and the knowledge graph uses internally-synchronized data structures. No external lock management needed.",
    "",
    "## Emergent Coordination",
    "",
    "The most interesting behavior in multi-agent memory systems is emergent. Nobody programs it. It arises from the interaction of individual agents with shared state.",
    "",
    "When Agent A frequently accesses \"authentication\" and \"JWT\" together, the Hebbian learning system strengthens that edge. When Agent B later queries anything related to \"authentication,\" the \"JWT\" connection is already strong — it surfaces automatically.",
    "",
    "Over time, the shared knowledge graph becomes a map of how the project actually works. Not documentation (which is always outdated) but a living, weighted, decaying representation of what matters right now.",
    "",
    "## The Cognitive Parallel",
    "",
    "This mirrors how human team cognition works. Psychologist Daniel Wegner called it \"transactive memory\" — the shared cognitive system that emerges when people work together. Team members learn who knows what, and the team's collective memory exceeds any individual's.",
    "",
    "In multi-agent systems, the shared memory IS the transactive memory. Agents don't need to learn \"who knows what\" because all knowledge is in a common substrate. But the same principle applies: the system's collective intelligence exceeds any single agent's.",
    "",
    "## Practical Patterns",
    "",
    "- **Decision logs**: Every architectural decision goes into shared memory with rationale. Future agents inherit context, not just outcomes.",
    "- **Error propagation**: When one agent discovers a bug pattern, all agents benefit on their next retrieval.",
    "- **Context inheritance**: A new agent joining the project gets immediate context from the shared memory — no onboarding needed.",
    "- **Preference convergence**: Over time, agents converge on consistent patterns because they're all learning from the same shared experiences.",
    "",
    "## What's Next",
    "",
    "Multi-agent memory is early. Conflict resolution is still naive (last-write-wins in most cases). There's no formal consistency model for shared knowledge graphs. Memory permissions (who can see what) are coarse-grained.",
    "",
    "But the core insight is sound: shared memory enables implicit coordination that's more robust than explicit protocols. When agents share a brain, they share understanding.",
  ],

  "embedding-models-edge-devices": [
    "# Running Embedding Models on Edge Devices: ONNX, Quantization, and Reality",
    "",
    "Getting a neural network to run on a Raspberry Pi sounds like a stunt. But for shodh-memory, it's a requirement — if the embedding model can't run locally, the entire offline-first promise collapses.",
    "",
    "Here's what it actually took to get MiniLM-L6-v2 running at 34ms per embedding on a $35 computer.",
    "",
    "## Why MiniLM-L6-v2",
    "",
    "Model selection for edge deployment is a constrained optimization problem:",
    "",
    "| Model | Dimensions | Size | Quality (STS) | Speed (Pi 4) |",
    "|-------|-----------|------|---------------|-------------|",
    "| all-MiniLM-L6-v2 | 384 | 22MB | 82.0 | 34ms |",
    "| all-MiniLM-L12-v2 | 384 | 33MB | 83.4 | 71ms |",
    "| all-mpnet-base-v2 | 768 | 420MB | 86.1 | 340ms |",
    "| BGE-large | 1024 | 1.3GB | 87.2 | OOM |",
    "",
    "MiniLM-L6-v2 hits the sweet spot: 82% quality at 34ms latency with only 22MB. The 1.4% quality improvement from L12 costs 2x latency. The jump to mpnet costs 10x latency and 20x model size. BGE-large doesn't fit in memory at all.",
    "",
    "For a memory system where semantic similarity needs to be \"good enough\" for retrieval (the knowledge graph and temporal index correct for imprecision), 82% STS is more than sufficient.",
    "",
    "## ONNX Runtime: The Deployment Story",
    "",
    "Training happens in PyTorch. Deployment happens in ONNX Runtime. The conversion is straightforward:",
    "",
    "```python",
    "# Export from PyTorch → ONNX",
    "torch.onnx.export(model, dummy_input, \"model.onnx\",",
    "    input_names=[\"input_ids\", \"attention_mask\", \"token_type_ids\"],",
    "    dynamic_axes={\"input_ids\": {0: \"batch\", 1: \"seq\"}})",
    "```",
    "",
    "ONNX Runtime gives us three things that PyTorch doesn't:",
    "",
    "- **No Python dependency**: The Rust `ort` crate links against the C++ ONNX Runtime directly. No Python interpreter on the Pi.",
    "- **Hardware optimization**: ONNX Runtime auto-selects optimal execution providers (CPU, CUDA, CoreML, NNAPI) based on available hardware.",
    "- **Minimal footprint**: The ONNX Runtime shared library is ~15MB. Compare to PyTorch's 800MB+ installation.",
    "",
    "## The Tokenization Pipeline",
    "",
    "The embedding pipeline is: Text → Tokenize → Model Inference → Mean Pooling → L2 Normalize.",
    "",
    "Tokenization is often the overlooked bottleneck. We use the `tokenizers` crate (from Hugging Face) compiled from Rust. It runs the WordPiece tokenizer in ~50 microseconds — negligible compared to model inference.",
    "",
    "```",
    "Pipeline Latency Breakdown (Raspberry Pi 4):",
    "  Tokenization:    0.05ms  (0.1%)",
    "  Model Inference: 33.00ms (97.1%)",
    "  Mean Pooling:    0.45ms  (1.3%)",
    "  L2 Normalize:    0.50ms  (1.5%)",
    "  Total:          34.00ms",
    "```",
    "",
    "Inference dominates. Everything else is noise.",
    "",
    "## Batch Processing for Throughput",
    "",
    "When storing multiple memories at once (e.g., during initial ingestion), batch processing amortizes the model loading overhead:",
    "",
    "```",
    "Single embedding:  34ms  (29 embeddings/sec)",
    "Batch of 8:       180ms  (44 embeddings/sec)",
    "Batch of 32:      650ms  (49 embeddings/sec)",
    "```",
    "",
    "Diminishing returns above batch size 8 on a Pi — the model's compute dominates, and larger batches just increase memory pressure. We default to batch size 8 for optimal throughput-per-watt.",
    "",
    "## The Circuit Breaker",
    "",
    "On edge devices, the embedding model can fail in creative ways: out of memory, thread pool exhaustion, corrupt model file, ONNX Runtime segfault. If the embedding pipeline fails, the entire memory system shouldn't go down.",
    "",
    "We use a circuit breaker pattern:",
    "",
    "```",
    "States: Closed (normal) → Open (failing) → Half-Open (testing)",
    "",
    "Closed:    Forward requests to ONNX Runtime normally",
    "Open:      Skip embeddings, return zero vectors (graceful degradation)",
    "Half-Open: Test one request, if OK → Closed, if fail → Open",
    "```",
    "",
    "When the circuit is open, shodh-memory degrades gracefully: vector search returns no results, but keyword search, knowledge graph traversal, and temporal retrieval still work. Memory is impaired but not dead.",
    "",
    "This is how the brain handles injury. Damage to one system doesn't bring everything down. The other cognitive systems compensate.",
    "",
    "## Model Pinning and Integrity",
    "",
    "We pin model URLs to specific HuggingFace commits with SHA-256 checksum verification. If the model file doesn't match the expected checksum, it's rejected and re-downloaded.",
    "",
    "This prevents supply-chain attacks (a compromised model that exfiltrates data) and ensures reproducibility (same model bytes on every device, every time).",
    "",
    "## The Bottom Line",
    "",
    "Running embeddings on edge devices is practical today. The trick is choosing the right model (small, fast, good enough), the right runtime (ONNX, not PyTorch), and building for failure (circuit breakers, graceful degradation).",
    "",
    "A 34ms embedding is fast enough for memory. Not for real-time video processing. But for remembering what happened in a conversation? More than sufficient.",
  ],

  "the-memory-layer": [
    "# The Memory Layer: Why Every AI System Will Have One by 2027",
    "",
    "The AI stack is missing a layer.",
    "",
    "We have the compute layer (GPUs, TPUs, inference engines). We have the storage layer (databases, object stores, vector DBs). We have the networking layer (APIs, protocols, MCP). We have the model layer (foundation models, fine-tuned models, LoRA adapters).",
    "",
    "But we don't have a memory layer. And that's why AI systems feel stupid even when the underlying models are brilliant.",
    "",
    "## What Is the Memory Layer?",
    "",
    "The memory layer sits between the model and the application. It provides cognitive state — the accumulated knowledge, preferences, experiences, and associations that make each interaction contextual rather than generic.",
    "",
    "```",
    "┌─────────────────────────────────────────┐",
    "│         Application Layer                 │",
    "│   (UI, API, agent orchestration)         │",
    "├─────────────────────────────────────────┤",
    "│         Memory Layer         ← THIS      │",
    "│   (cognitive state, learning, recall)    │",
    "├─────────────────────────────────────────┤",
    "│         Model Layer                       │",
    "│   (LLMs, embeddings, fine-tuned models)  │",
    "├─────────────────────────────────────────┤",
    "│         Infrastructure Layer              │",
    "│   (compute, storage, networking)         │",
    "└─────────────────────────────────────────┘",
    "```",
    "",
    "Without the memory layer, every session is isolated. The model generates based on the current prompt and nothing else. It's like talking to someone with amnesia — they might be brilliant in the moment, but they can't build on past conversations.",
    "",
    "## Why Now",
    "",
    "Three things converged to make the memory layer possible and necessary:",
    "",
    "### 1. Agents Need State",
    "",
    "The shift from chatbots to agents changes everything. A chatbot handles one request and forgets. An agent handles a project over days, weeks, months. Without persistent memory, agents are just chatbots that loop.",
    "",
    "### 2. MCP Created the Interface",
    "",
    "Model Context Protocol standardized how AI models access external tools. Memory systems can plug into any MCP-compatible client — Claude, Cursor, custom agents — through a universal interface. This eliminates the integration bottleneck.",
    "",
    "### 3. Edge Computing Made It Local",
    "",
    "Embedding models now run on consumer hardware. Vector search algorithms handle millions of vectors on a laptop. The memory layer doesn't need a cloud — it runs where the agent runs.",
    "",
    "## What the Memory Layer Does",
    "",
    "A proper memory layer provides five cognitive capabilities:",
    "",
    "### Encoding",
    "Converting raw experiences into structured, retrievable memories. Not just \"store this text\" but \"extract entities, form relationships, assign importance, embed semantically.\"",
    "",
    "### Consolidation",
    "Deciding what to keep and what to forget. Fresh memories decay. Frequently-accessed memories strengthen. Important connections are reinforced through Hebbian learning. Noise is pruned through natural decay.",
    "",
    "### Retrieval",
    "Surfacing relevant context when needed — and before it's asked for. Proactive retrieval based on the current conversation, not just reactive search from explicit queries.",
    "",
    "### Association",
    "Connecting related concepts through a knowledge graph. When you access one memory, related memories activate. This is spreading activation — the mechanism that makes human memory feel effortless.",
    "",
    "### Learning",
    "Getting better over time. The memory layer should improve its retrieval quality, strengthen useful associations, and adapt to the user's patterns. This isn't fine-tuning — it's the memory becoming more efficient at surfacing what matters.",
    "",
    "## Memory as Competitive Moat",
    "",
    "Here's the business case: models are commoditizing. GPT-4, Claude, Gemini — they're converging in capability. The differentiator isn't the model. It's the context the model has access to.",
    "",
    "An AI assistant with three months of accumulated memory about your codebase, your preferences, your team's decisions, and your project's history is fundamentally more useful than a fresh instance of a marginally better model.",
    "",
    "Memory creates switching costs. Not artificial lock-in — genuine value accumulation. The more you use a memory-augmented system, the more it knows, the better it works, the harder it is to start over with something else.",
    "",
    "## The Architecture of the Layer",
    "",
    "The memory layer isn't one technology. It's a composition:",
    "",
    "- **Vector store** for semantic similarity (\"find memories about database optimization\")",
    "- **Knowledge graph** for associative retrieval (\"what else relates to PostgreSQL in this project?\")",
    "- **Temporal index** for recency and sequence (\"what happened in the last session?\")",
    "- **Decay engine** for automatic pruning (\"forget the debugging session from 3 months ago\")",
    "- **Learning system** for adaptation (\"this connection keeps getting accessed, make it permanent\")",
    "",
    "No single database handles all of this. The memory layer is a cognitive system, not a storage system.",
    "",
    "## Predictions",
    "",
    "- By end of 2026, every major AI coding assistant will have persistent memory",
    "- By 2027, \"stateless AI\" will feel as primitive as websites without cookies",
    "- The memory layer will become a standard infrastructure component, like caching or queuing",
    "- Edge-first memory will win over cloud-first because latency and privacy matter",
    "- Open standards (MCP) will prevent vendor lock-in at the protocol level",
    "",
    "The compute layer took a decade to mature. The memory layer will move faster — the research is done, the models are capable, and the demand is obvious.",
    "",
    "The question isn't whether AI systems will have a memory layer. It's whether you'll build one or buy one.",
  ],
};

export async function generateMetadata({
  params,
}: {
  params: Promise<{ slug: string }>;
}): Promise<Metadata> {
  const { slug } = await params;
  const post = BLOG_POSTS.find((p) => p.slug === slug);

  if (!post) {
    return { title: "Post Not Found" };
  }

  return {
    title: post.title,
    description: post.excerpt,
    openGraph: {
      title: post.title,
      description: post.excerpt,
      type: "article",
      publishedTime: post.date,
      tags: post.tags,
      url: `https://www.shodh-memory.com/blog/${post.slug}`,
      siteName: "shodh-memory",
    },
    twitter: {
      card: "summary_large_image",
      title: post.title,
      description: post.excerpt,
      creator: "@shodh_memory",
    },
    alternates: {
      canonical: `https://www.shodh-memory.com/blog/${post.slug}`,
    },
  };
}

export async function generateStaticParams() {
  return BLOG_POSTS.map((post) => ({
    slug: post.slug,
  }));
}

export default async function BlogPost({ params }: { params: Promise<{ slug: string }> }) {
  const { slug } = await params;
  const post = BLOG_POSTS.find((p) => p.slug === slug);

  if (!post) {
    notFound();
  }

  const content = BLOG_CONTENT[slug] || ["# Coming Soon", "", "This post is being written."];

  return (
    <div className="min-h-screen">
      <Header />
      <main className="pt-24 pb-16 px-4">
        <div className="mx-auto max-w-3xl">
          <Link href="/blog" className="text-[var(--term-text-dim)] hover:text-[var(--term-orange)] text-sm mb-8 inline-block">
            ← Back to blog
          </Link>

          <article>
            <header className="mb-8">
              <div className="flex items-center gap-4 text-sm text-[var(--term-text-dim)] mb-4">
                <span>{post.date}</span>
                <span>•</span>
                <span>{post.readTime} read</span>
              </div>
              <h1 className="text-2xl md:text-3xl font-semibold text-[var(--term-text)] mb-4">{post.title}</h1>
              <div className="flex gap-2">
                {post.tags.map((tag, i) => (
                  <span key={i} className="text-xs px-2 py-1 border border-[var(--term-border)] text-[var(--term-text-dim)]">
                    {tag}
                  </span>
                ))}
              </div>
            </header>

            <div className="shadow-window">
              <div className="terminal-header">
                <div className="terminal-dot terminal-dot-red" />
                <div className="terminal-dot terminal-dot-yellow" />
                <div className="terminal-dot terminal-dot-green" />
                <span className="ml-2 text-[var(--term-text-dim)] text-sm">{slug}.md</span>
              </div>
              <div className="terminal-body prose-terminal">
                {content.map((line, i) => (
                  <div key={i} className="leading-relaxed">
                    {line.startsWith("# ") ? (
                      <h1 className="text-xl font-bold text-[var(--term-orange)] mt-6 mb-4">{line.slice(2)}</h1>
                    ) : line.startsWith("## ") ? (
                      <h2 className="text-lg font-semibold text-[var(--term-orange)] mt-6 mb-3">{line.slice(3)}</h2>
                    ) : line.startsWith("### ") ? (
                      <h3 className="text-base font-medium text-[var(--term-text)] mt-4 mb-2">{line.slice(4)}</h3>
                    ) : line.startsWith("```") ? (
                      <div className="text-[var(--term-text-dim)] text-xs">{line}</div>
                    ) : line.startsWith("- ") || line.startsWith("* ") ? (
                      <div className="text-[var(--term-text-dim)] pl-4">• {line.slice(2)}</div>
                    ) : line.startsWith("|") ? (
                      <div className="text-[var(--term-text-dim)] font-mono text-xs">{line}</div>
                    ) : line === "" ? (
                      <div className="h-4" />
                    ) : (
                      <p className="text-[var(--term-text-dim)]">{line}</p>
                    )}
                  </div>
                ))}
              </div>
            </div>
          </article>

          <div className="mt-12 pt-8 border-t border-[var(--term-border)]">
            <Link href="/blog" className="text-[var(--term-orange)] hover:underline">
              ← More posts
            </Link>
          </div>
        </div>
      </main>
      <Footer />
    </div>
  );
}
